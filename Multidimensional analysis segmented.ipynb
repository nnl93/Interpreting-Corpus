{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train dataset\n",
    "ToRCH2014 (Texts of Recent Chinese, Brown family), obtained from http://corpus.bfsu.edu.cn/corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['女士', '们', '，', '先生', '们', '，', '上午', '好', '。', '我们', ...]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "import os\n",
    "import nltk \n",
    "from nltk.corpus import CategorizedPlaintextCorpusReader\n",
    "corpus = CategorizedPlaintextCorpusReader(\n",
    "    '/users/nannanliu/Python/SCIPPC/original_Chinese/segmented',\n",
    "    r'(?!\\.).*\\.txt',\n",
    "    cat_pattern=os.path.join(r'(neg|pos)', '.*',),\n",
    "    encoding='utf-8')\n",
    "corpus.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_A01A_SEG.txt\n",
      "ToRCH2014_A01B_SEG.txt\n",
      "ToRCH2014_A02A_SEG.txt\n",
      "ToRCH2014_A02B_SEG.txt\n",
      "ToRCH2014_A03_SEG.txt\n",
      "ToRCH2014_A04A_SEG.txt\n",
      "ToRCH2014_A04B_SEG.txt\n",
      "ToRCH2014_A04C_SEG.txt\n",
      "ToRCH2014_A05_SEG.txt\n",
      "ToRCH2014_A06A_SEG.txt\n",
      "ToRCH2014_A06B_SEG.txt\n",
      "ToRCH2014_A06C_SEG.txt\n",
      "ToRCH2014_A07A_SEG.txt\n",
      "ToRCH2014_A07B_SEG.txt\n",
      "ToRCH2014_A07C_SEG.txt\n",
      "ToRCH2014_A07D_SEG.txt\n",
      "ToRCH2014_A08A_SEG.txt\n",
      "ToRCH2014_A08B_SEG.txt\n",
      "ToRCH2014_A08C_SEG.txt\n",
      "ToRCH2014_A09A_SEG.txt\n",
      "ToRCH2014_A09B_SEG.txt\n",
      "ToRCH2014_A09C_SEG.txt\n",
      "ToRCH2014_A10_SEG.txt\n",
      "ToRCH2014_A11_SEG.txt\n",
      "ToRCH2014_A12A_SEG.txt\n",
      "ToRCH2014_A12B_SEG.txt\n",
      "ToRCH2014_A13_SEG.txt\n",
      "ToRCH2014_A14A_SEG.txt\n",
      "ToRCH2014_A14B_SEG.txt\n",
      "ToRCH2014_A15A_SEG.txt\n",
      "ToRCH2014_A15B_SEG.txt\n",
      "ToRCH2014_A16A_SEG.txt\n",
      "ToRCH2014_A16B_SEG.txt\n",
      "ToRCH2014_A17A_SEG.txt\n",
      "ToRCH2014_A17B_SEG.txt\n",
      "ToRCH2014_A17C_SEG.txt\n",
      "ToRCH2014_A18A_SEG.txt\n",
      "ToRCH2014_A18B_SEG.txt\n",
      "ToRCH2014_A18C_SEG.txt\n",
      "ToRCH2014_A18D_SEG.txt\n",
      "ToRCH2014_A19A_SEG.txt\n",
      "ToRCH2014_A19B_SEG.txt\n",
      "ToRCH2014_A20_SEG.txt\n",
      "ToRCH2014_A21A_SEG.txt\n",
      "ToRCH2014_A21B_SEG.txt\n",
      "ToRCH2014_A22A_SEG.txt\n",
      "ToRCH2014_A22B_SEG.txt\n",
      "ToRCH2014_A22C_SEG.txt\n",
      "ToRCH2014_A22D_SEG.txt\n",
      "ToRCH2014_A23A_SEG.txt\n",
      "ToRCH2014_A23B_SEG.txt\n",
      "ToRCH2014_A23C_SEG.txt\n",
      "ToRCH2014_A24A_SEG.txt\n",
      "ToRCH2014_A24B_SEG.txt\n",
      "ToRCH2014_A24C_SEG.txt\n",
      "ToRCH2014_A25A_SEG.txt\n",
      "ToRCH2014_A25B_SEG.txt\n",
      "ToRCH2014_A25C_SEG.txt\n",
      "ToRCH2014_A26_SEG.txt\n",
      "ToRCH2014_A27A_SEG.txt\n",
      "ToRCH2014_A27B_SEG.txt\n",
      "ToRCH2014_A27C_SEG.txt\n",
      "ToRCH2014_A27D_SEG.txt\n",
      "ToRCH2014_A28A_SEG.txt\n",
      "ToRCH2014_A28B_SEG.txt\n",
      "ToRCH2014_A28C_SEG.txt\n",
      "ToRCH2014_A28D_SEG.txt\n",
      "ToRCH2014_A28E_SEG.txt\n",
      "ToRCH2014_A29A_SEG.txt\n",
      "ToRCH2014_A29B_SEG.txt\n",
      "ToRCH2014_A30A_SEG.txt\n",
      "ToRCH2014_A30B_SEG.txt\n",
      "ToRCH2014_A30C_SEG.txt\n",
      "ToRCH2014_A31A_SEG.txt\n",
      "ToRCH2014_A31B_SEG.txt\n",
      "ToRCH2014_A32_SEG.txt\n",
      "ToRCH2014_A33A_SEG.txt\n",
      "ToRCH2014_A33B_SEG.txt\n",
      "ToRCH2014_A33C_SEG.txt\n",
      "ToRCH2014_A34A_SEG.txt\n",
      "ToRCH2014_A34B_SEG.txt\n",
      "ToRCH2014_A35A_SEG.txt\n",
      "ToRCH2014_A35B_SEG.txt\n",
      "ToRCH2014_A35C_SEG.txt\n",
      "ToRCH2014_A36_SEG.txt\n",
      "ToRCH2014_A37A_SEG.txt\n",
      "ToRCH2014_A37B_SEG.txt\n",
      "ToRCH2014_A37C_SEG.txt\n",
      "ToRCH2014_A38A_SEG.txt\n",
      "ToRCH2014_A38B_SEG.txt\n",
      "ToRCH2014_A38C_SEG.txt\n",
      "ToRCH2014_A39A_SEG.txt\n",
      "ToRCH2014_A39B_SEG.txt\n",
      "ToRCH2014_A40A_SEG.txt\n",
      "ToRCH2014_A40B_SEG.txt\n",
      "ToRCH2014_A40C_SEG.txt\n",
      "ToRCH2014_A41A_SEG.txt\n",
      "ToRCH2014_A41B_SEG.txt\n",
      "ToRCH2014_A42A_SEG.txt\n",
      "ToRCH2014_A42B_SEG.txt\n",
      "ToRCH2014_A43A_SEG.txt\n",
      "ToRCH2014_A43B_SEG.txt\n",
      "ToRCH2014_A44_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#ToRCH contains 15 text types, here get type A reportage\n",
    "import fileinput\n",
    "import fnmatch\n",
    "\n",
    "files=corpus.fileids()\n",
    "\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_A*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToRCH contains 15 text types, here get type A reportage    \n",
    "reportage_files=['ToRCH2014_A01A_SEG.txt', 'ToRCH2014_A01B_SEG.txt', 'ToRCH2014_A02A_SEG.txt', 'ToRCH2014_A02B_SEG.txt', 'ToRCH2014_A03_SEG.txt', 'ToRCH2014_A04A_SEG.txt', 'ToRCH2014_A04B_SEG.txt', 'ToRCH2014_A04C_SEG.txt', 'ToRCH2014_A05_SEG.txt', 'ToRCH2014_A06A_SEG.txt', 'ToRCH2014_A06B_SEG.txt', 'ToRCH2014_A06C_SEG.txt', 'ToRCH2014_A07A_SEG.txt', 'ToRCH2014_A07B_SEG.txt', 'ToRCH2014_A07C_SEG.txt', 'ToRCH2014_A07D_SEG.txt', 'ToRCH2014_A08A_SEG.txt', 'ToRCH2014_A08B_SEG.txt', 'ToRCH2014_A08C_SEG.txt', 'ToRCH2014_A09A_SEG.txt', 'ToRCH2014_A09B_SEG.txt', 'ToRCH2014_A09C_SEG.txt', 'ToRCH2014_A10_SEG.txt', 'ToRCH2014_A11_SEG.txt', 'ToRCH2014_A12A_SEG.txt', 'ToRCH2014_A12B_SEG.txt', 'ToRCH2014_A13_SEG.txt', 'ToRCH2014_A14A_SEG.txt', 'ToRCH2014_A14B_SEG.txt', 'ToRCH2014_A15A_SEG.txt', 'ToRCH2014_A15B_SEG.txt', 'ToRCH2014_A16A_SEG.txt', 'ToRCH2014_A16B_SEG.txt', 'ToRCH2014_A17A_SEG.txt', 'ToRCH2014_A17B_SEG.txt', 'ToRCH2014_A17C_SEG.txt', 'ToRCH2014_A18A_SEG.txt', 'ToRCH2014_A18B_SEG.txt', 'ToRCH2014_A18C_SEG.txt', 'ToRCH2014_A18D_SEG.txt', 'ToRCH2014_A19A_SEG.txt', 'ToRCH2014_A19B_SEG.txt', 'ToRCH2014_A20_SEG.txt', 'ToRCH2014_A21A_SEG.txt', 'ToRCH2014_A21B_SEG.txt', 'ToRCH2014_A22A_SEG.txt', 'ToRCH2014_A22B_SEG.txt', 'ToRCH2014_A22C_SEG.txt', 'ToRCH2014_A22D_SEG.txt', 'ToRCH2014_A23A_SEG.txt', 'ToRCH2014_A23B_SEG.txt', 'ToRCH2014_A23C_SEG.txt', 'ToRCH2014_A24A_SEG.txt', 'ToRCH2014_A24B_SEG.txt', 'ToRCH2014_A24C_SEG.txt', 'ToRCH2014_A25A_SEG.txt', 'ToRCH2014_A25B_SEG.txt', 'ToRCH2014_A25C_SEG.txt', 'ToRCH2014_A26_SEG.txt', 'ToRCH2014_A27A_SEG.txt', 'ToRCH2014_A27B_SEG.txt', 'ToRCH2014_A27C_SEG.txt', 'ToRCH2014_A27D_SEG.txt', 'ToRCH2014_A28A_SEG.txt', 'ToRCH2014_A28B_SEG.txt', 'ToRCH2014_A28C_SEG.txt', 'ToRCH2014_A28D_SEG.txt', 'ToRCH2014_A28E_SEG.txt', 'ToRCH2014_A29A_SEG.txt', 'ToRCH2014_A29B_SEG.txt', 'ToRCH2014_A30A_SEG.txt', 'ToRCH2014_A30B_SEG.txt', 'ToRCH2014_A30C_SEG.txt', 'ToRCH2014_A31A_SEG.txt', 'ToRCH2014_A31B_SEG.txt', 'ToRCH2014_A32_SEG.txt', 'ToRCH2014_A33A_SEG.txt', 'ToRCH2014_A33B_SEG.txt', 'ToRCH2014_A33C_SEG.txt', 'ToRCH2014_A34A_SEG.txt', 'ToRCH2014_A34B_SEG.txt', 'ToRCH2014_A35A_SEG.txt', 'ToRCH2014_A35B_SEG.txt', 'ToRCH2014_A35C_SEG.txt', 'ToRCH2014_A36_SEG.txt', 'ToRCH2014_A37A_SEG.txt', 'ToRCH2014_A37B_SEG.txt', 'ToRCH2014_A37C_SEG.txt', 'ToRCH2014_A38A_SEG.txt', 'ToRCH2014_A38B_SEG.txt', 'ToRCH2014_A38C_SEG.txt', 'ToRCH2014_A39A_SEG.txt', 'ToRCH2014_A39B_SEG.txt', 'ToRCH2014_A40A_SEG.txt', 'ToRCH2014_A40B_SEG.txt', 'ToRCH2014_A40C_SEG.txt', 'ToRCH2014_A41A_SEG.txt', 'ToRCH2014_A41B_SEG.txt', 'ToRCH2014_A42A_SEG.txt', 'ToRCH2014_A42B_SEG.txt', 'ToRCH2014_A43A_SEG.txt', 'ToRCH2014_A43B_SEG.txt', 'ToRCH2014_A44_SEG.txt']\n",
    "reportage=corpus.words(reportage_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reportage.count('习近平')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_B01A_SEG.txt\n",
      "ToRCH2014_B01B_SEG.txt\n",
      "ToRCH2014_B01C_SEG.txt\n",
      "ToRCH2014_B02A_SEG.txt\n",
      "ToRCH2014_B02B_SEG.txt\n",
      "ToRCH2014_B02C_SEG.txt\n",
      "ToRCH2014_B02D_SEG.txt\n",
      "ToRCH2014_B03A_SEG.txt\n",
      "ToRCH2014_B03B_SEG.txt\n",
      "ToRCH2014_B03C_SEG.txt\n",
      "ToRCH2014_B04A_SEG.txt\n",
      "ToRCH2014_B04B_SEG.txt\n",
      "ToRCH2014_B04C_SEG.txt\n",
      "ToRCH2014_B05A_SEG.txt\n",
      "ToRCH2014_B05B_SEG.txt\n",
      "ToRCH2014_B05C_SEG.txt\n",
      "ToRCH2014_B06A_SEG.txt\n",
      "ToRCH2014_B06B_SEG.txt\n",
      "ToRCH2014_B06C_SEG.txt\n",
      "ToRCH2014_B06D_SEG.txt\n",
      "ToRCH2014_B07A_SEG.txt\n",
      "ToRCH2014_B07B_SEG.txt\n",
      "ToRCH2014_B07C_SEG.txt\n",
      "ToRCH2014_B08A_SEG.txt\n",
      "ToRCH2014_B08B_SEG.txt\n",
      "ToRCH2014_B08C_SEG.txt\n",
      "ToRCH2014_B08D_SEG.txt\n",
      "ToRCH2014_B09A_SEG.txt\n",
      "ToRCH2014_B09B_SEG.txt\n",
      "ToRCH2014_B10A_SEG.txt\n",
      "ToRCH2014_B10B_SEG.txt\n",
      "ToRCH2014_B11A_SEG.txt\n",
      "ToRCH2014_B11B_SEG.txt\n",
      "ToRCH2014_B11C_SEG.txt\n",
      "ToRCH2014_B12A_SEG.txt\n",
      "ToRCH2014_B12B_SEG.txt\n",
      "ToRCH2014_B12C_SEG.txt\n",
      "ToRCH2014_B13A_SEG.txt\n",
      "ToRCH2014_B13B_SEG.txt\n",
      "ToRCH2014_B13C_SEG.txt\n",
      "ToRCH2014_B13D_SEG.txt\n",
      "ToRCH2014_B14A_SEG.txt\n",
      "ToRCH2014_B14B_SEG.txt\n",
      "ToRCH2014_B14C_SEG.txt\n",
      "ToRCH2014_B15A_SEG.txt\n",
      "ToRCH2014_B15B_SEG.txt\n",
      "ToRCH2014_B15C_SEG.txt\n",
      "ToRCH2014_B16A_SEG.txt\n",
      "ToRCH2014_B16B_SEG.txt\n",
      "ToRCH2014_B16C_SEG.txt\n",
      "ToRCH2014_B17A_SEG.txt\n",
      "ToRCH2014_B17B_SEG.txt\n",
      "ToRCH2014_B17C_SEG.txt\n",
      "ToRCH2014_B18A_SEG.txt\n",
      "ToRCH2014_B18B_SEG.txt\n",
      "ToRCH2014_B19A_SEG.txt\n",
      "ToRCH2014_B19B_SEG.txt\n",
      "ToRCH2014_B19C_SEG.txt\n",
      "ToRCH2014_B19D_SEG.txt\n",
      "ToRCH2014_B20A_SEG.txt\n",
      "ToRCH2014_B20B_SEG.txt\n",
      "ToRCH2014_B20C_SEG.txt\n",
      "ToRCH2014_B20D_SEG.txt\n",
      "ToRCH2014_B21A_SEG.txt\n",
      "ToRCH2014_B21B_SEG.txt\n",
      "ToRCH2014_B21C_SEG.txt\n",
      "ToRCH2014_B22A_SEG.txt\n",
      "ToRCH2014_B22B_SEG.txt\n",
      "ToRCH2014_B22C_SEG.txt\n",
      "ToRCH2014_B23A_SEG.txt\n",
      "ToRCH2014_B23B_SEG.txt\n",
      "ToRCH2014_B24A_SEG.txt\n",
      "ToRCH2014_B24B_SEG.txt\n",
      "ToRCH2014_B25A_SEG.txt\n",
      "ToRCH2014_B25B_SEG.txt\n",
      "ToRCH2014_B26A_SEG.txt\n",
      "ToRCH2014_B26B_SEG.txt\n",
      "ToRCH2014_B26C_SEG.txt\n",
      "ToRCH2014_B27_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type B editorials\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_B*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "editorial_files=['ToRCH2014_B01A_SEG.txt', 'ToRCH2014_B01B_SEG.txt', 'ToRCH2014_B01C_SEG.txt', 'ToRCH2014_B02A_SEG.txt', 'ToRCH2014_B02B_SEG.txt', 'ToRCH2014_B02C_SEG.txt', 'ToRCH2014_B02D_SEG.txt', 'ToRCH2014_B03A_SEG.txt', 'ToRCH2014_B03B_SEG.txt', 'ToRCH2014_B03C_SEG.txt', 'ToRCH2014_B04A_SEG.txt', 'ToRCH2014_B04B_SEG.txt', 'ToRCH2014_B04C_SEG.txt', 'ToRCH2014_B05A_SEG.txt', 'ToRCH2014_B05B_SEG.txt', 'ToRCH2014_B05C_SEG.txt', 'ToRCH2014_B06A_SEG.txt', 'ToRCH2014_B06B_SEG.txt', 'ToRCH2014_B06C_SEG.txt', 'ToRCH2014_B06D_SEG.txt', 'ToRCH2014_B07A_SEG.txt', 'ToRCH2014_B07B_SEG.txt', 'ToRCH2014_B07C_SEG.txt', 'ToRCH2014_B08A_SEG.txt', 'ToRCH2014_B08B_SEG.txt', 'ToRCH2014_B08C_SEG.txt', 'ToRCH2014_B08D_SEG.txt', 'ToRCH2014_B09A_SEG.txt', 'ToRCH2014_B09B_SEG.txt', 'ToRCH2014_B10A_SEG.txt', 'ToRCH2014_B10B_SEG.txt', 'ToRCH2014_B11A_SEG.txt', 'ToRCH2014_B11B_SEG.txt', 'ToRCH2014_B11C_SEG.txt', 'ToRCH2014_B12A_SEG.txt', 'ToRCH2014_B12B_SEG.txt', 'ToRCH2014_B12C_SEG.txt', 'ToRCH2014_B13A_SEG.txt', 'ToRCH2014_B13B_SEG.txt', 'ToRCH2014_B13C_SEG.txt', 'ToRCH2014_B13D_SEG.txt', 'ToRCH2014_B14A_SEG.txt', 'ToRCH2014_B14B_SEG.txt', 'ToRCH2014_B14C_SEG.txt', 'ToRCH2014_B15A_SEG.txt', 'ToRCH2014_B15B_SEG.txt', 'ToRCH2014_B15C_SEG.txt', 'ToRCH2014_B16A_SEG.txt', 'ToRCH2014_B16B_SEG.txt', 'ToRCH2014_B16C_SEG.txt', 'ToRCH2014_B17A_SEG.txt', 'ToRCH2014_B17B_SEG.txt', 'ToRCH2014_B17C_SEG.txt', 'ToRCH2014_B18A_SEG.txt', 'ToRCH2014_B18B_SEG.txt', 'ToRCH2014_B19A_SEG.txt', 'ToRCH2014_B19B_SEG.txt', 'ToRCH2014_B19C_SEG.txt', 'ToRCH2014_B19D_SEG.txt', 'ToRCH2014_B20A_SEG.txt', 'ToRCH2014_B20B_SEG.txt', 'ToRCH2014_B20C_SEG.txt', 'ToRCH2014_B20D_SEG.txt', 'ToRCH2014_B21A_SEG.txt', 'ToRCH2014_B21B_SEG.txt', 'ToRCH2014_B21C_SEG.txt', 'ToRCH2014_B22A_SEG.txt', 'ToRCH2014_B22B_SEG.txt', 'ToRCH2014_B22C_SEG.txt', 'ToRCH2014_B23A_SEG.txt', 'ToRCH2014_B23B_SEG.txt', 'ToRCH2014_B24A_SEG.txt', 'ToRCH2014_B24B_SEG.txt', 'ToRCH2014_B25A_SEG.txt', 'ToRCH2014_B25B_SEG.txt', 'ToRCH2014_B26A_SEG.txt', 'ToRCH2014_B26B_SEG.txt', 'ToRCH2014_B26C_SEG.txt', 'ToRCH2014_B27_SEG.txt']\n",
    "editorial=corpus.words(editorial_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_C01_SEG.txt\n",
      "ToRCH2014_C02A_SEG.txt\n",
      "ToRCH2014_C02B_SEG.txt\n",
      "ToRCH2014_C03A_SEG.txt\n",
      "ToRCH2014_C03B_SEG.txt\n",
      "ToRCH2014_C04A_SEG.txt\n",
      "ToRCH2014_C04B_SEG.txt\n",
      "ToRCH2014_C05A_SEG.txt\n",
      "ToRCH2014_C05B_SEG.txt\n",
      "ToRCH2014_C06_SEG.txt\n",
      "ToRCH2014_C07_SEG.txt\n",
      "ToRCH2014_C08A_SEG.txt\n",
      "ToRCH2014_C08B_SEG.txt\n",
      "ToRCH2014_C09_SEG.txt\n",
      "ToRCH2014_C10A_SEG.txt\n",
      "ToRCH2014_C10B_SEG.txt\n",
      "ToRCH2014_C11A_SEG.txt\n",
      "ToRCH2014_C11B_SEG.txt\n",
      "ToRCH2014_C12A_SEG.txt\n",
      "ToRCH2014_C12B_SEG.txt\n",
      "ToRCH2014_C13A_SEG.txt\n",
      "ToRCH2014_C13B_SEG.txt\n",
      "ToRCH2014_C14A_SEG.txt\n",
      "ToRCH2014_C14B_SEG.txt\n",
      "ToRCH2014_C14C_SEG.txt\n",
      "ToRCH2014_C15A_SEG.txt\n",
      "ToRCH2014_C15B_SEG.txt\n",
      "ToRCH2014_C16_SEG.txt\n",
      "ToRCH2014_C17A_SEG.txt\n",
      "ToRCH2014_C17B_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type C press reviews\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_C*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_files=['ToRCH2014_C01_SEG.txt', 'ToRCH2014_C02A_SEG.txt', 'ToRCH2014_C02B_SEG.txt', 'ToRCH2014_C03A_SEG.txt', 'ToRCH2014_C03B_SEG.txt', 'ToRCH2014_C04A_SEG.txt', 'ToRCH2014_C04B_SEG.txt', 'ToRCH2014_C05A_SEG.txt', 'ToRCH2014_C05B_SEG.txt', 'ToRCH2014_C06_SEG.txt', 'ToRCH2014_C07_SEG.txt', 'ToRCH2014_C08A_SEG.txt', 'ToRCH2014_C08B_SEG.txt', 'ToRCH2014_C09_SEG.txt', 'ToRCH2014_C10A_SEG.txt', 'ToRCH2014_C10B_SEG.txt', 'ToRCH2014_C11A_SEG.txt', 'ToRCH2014_C11B_SEG.txt', 'ToRCH2014_C12A_SEG.txt', 'ToRCH2014_C12B_SEG.txt', 'ToRCH2014_C13A_SEG.txt', 'ToRCH2014_C13B_SEG.txt', 'ToRCH2014_C14A_SEG.txt', 'ToRCH2014_C14B_SEG.txt', 'ToRCH2014_C14C_SEG.txt', 'ToRCH2014_C15A_SEG.txt', 'ToRCH2014_C15B_SEG.txt', 'ToRCH2014_C16_SEG.txt', 'ToRCH2014_C17A_SEG.txt', 'ToRCH2014_C17B_SEG.txt']\n",
    "review=corpus.words(review_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_D01A_SEG.txt\n",
      "ToRCH2014_D01B_SEG.txt\n",
      "ToRCH2014_D02_SEG.txt\n",
      "ToRCH2014_D03A_SEG.txt\n",
      "ToRCH2014_D03B_SEG.txt\n",
      "ToRCH2014_D04A_SEG.txt\n",
      "ToRCH2014_D04B_SEG.txt\n",
      "ToRCH2014_D05A_SEG.txt\n",
      "ToRCH2014_D05B_SEG.txt\n",
      "ToRCH2014_D05C_SEG.txt\n",
      "ToRCH2014_D06_SEG.txt\n",
      "ToRCH2014_D07_SEG.txt\n",
      "ToRCH2014_D08_SEG.txt\n",
      "ToRCH2014_D09_SEG.txt\n",
      "ToRCH2014_D10_SEG.txt\n",
      "ToRCH2014_D11_SEG.txt\n",
      "ToRCH2014_D12_SEG.txt\n",
      "ToRCH2014_D13_SEG.txt\n",
      "ToRCH2014_D14A_SEG.txt\n",
      "ToRCH2014_D14B_SEG.txt\n",
      "ToRCH2014_D14C_SEG.txt\n",
      "ToRCH2014_D15_SEG.txt\n",
      "ToRCH2014_D16_SEG.txt\n",
      "ToRCH2014_D17_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type D religion\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_D*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion_files=['ToRCH2014_D01A_SEG.txt', 'ToRCH2014_D01B_SEG.txt', 'ToRCH2014_D02_SEG.txt', 'ToRCH2014_D03A_SEG.txt', 'ToRCH2014_D03B_SEG.txt', 'ToRCH2014_D04A_SEG.txt', 'ToRCH2014_D04B_SEG.txt', 'ToRCH2014_D05A_SEG.txt', 'ToRCH2014_D05B_SEG.txt', 'ToRCH2014_D05C_SEG.txt', 'ToRCH2014_D06_SEG.txt', 'ToRCH2014_D07_SEG.txt', 'ToRCH2014_D08_SEG.txt', 'ToRCH2014_D09_SEG.txt', 'ToRCH2014_D10_SEG.txt', 'ToRCH2014_D11_SEG.txt', 'ToRCH2014_D12_SEG.txt', 'ToRCH2014_D13_SEG.txt', 'ToRCH2014_D14A_SEG.txt', 'ToRCH2014_D14B_SEG.txt', 'ToRCH2014_D14C_SEG.txt', 'ToRCH2014_D15_SEG.txt', 'ToRCH2014_D16_SEG.txt', 'ToRCH2014_D17_SEG.txt']\n",
    "religion=corpus.words(religion_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_E01_SEG.txt\n",
      "ToRCH2014_E02_SEG.txt\n",
      "ToRCH2014_E03_SEG.txt\n",
      "ToRCH2014_E04A_SEG.txt\n",
      "ToRCH2014_E04B_SEG.txt\n",
      "ToRCH2014_E05A_SEG.txt\n",
      "ToRCH2014_E05B_SEG.txt\n",
      "ToRCH2014_E06_SEG.txt\n",
      "ToRCH2014_E07A_SEG.txt\n",
      "ToRCH2014_E07B_SEG.txt\n",
      "ToRCH2014_E07C_SEG.txt\n",
      "ToRCH2014_E08_SEG.txt\n",
      "ToRCH2014_E09A_SEG.txt\n",
      "ToRCH2014_E09B_SEG.txt\n",
      "ToRCH2014_E09C_SEG.txt\n",
      "ToRCH2014_E10A_SEG.txt\n",
      "ToRCH2014_E10B_SEG.txt\n",
      "ToRCH2014_E11A_SEG.txt\n",
      "ToRCH2014_E11B_SEG.txt\n",
      "ToRCH2014_E12A_SEG.txt\n",
      "ToRCH2014_E12B_SEG.txt\n",
      "ToRCH2014_E13A_SEG.txt\n",
      "ToRCH2014_E13B_SEG.txt\n",
      "ToRCH2014_E14A_SEG.txt\n",
      "ToRCH2014_E14B_SEG.txt\n",
      "ToRCH2014_E15A_SEG.txt\n",
      "ToRCH2014_E15B_SEG.txt\n",
      "ToRCH2014_E16_SEG.txt\n",
      "ToRCH2014_E17A_SEG.txt\n",
      "ToRCH2014_E17B_SEG.txt\n",
      "ToRCH2014_E18A_SEG.txt\n",
      "ToRCH2014_E18B_SEG.txt\n",
      "ToRCH2014_E19A_SEG.txt\n",
      "ToRCH2014_E19B_SEG.txt\n",
      "ToRCH2014_E20A_SEG.txt\n",
      "ToRCH2014_E20B_SEG.txt\n",
      "ToRCH2014_E21_SEG.txt\n",
      "ToRCH2014_E22A_SEG.txt\n",
      "ToRCH2014_E22B_SEG.txt\n",
      "ToRCH2014_E23_SEG.txt\n",
      "ToRCH2014_E24_SEG.txt\n",
      "ToRCH2014_E25_SEG.txt\n",
      "ToRCH2014_E26_SEG.txt\n",
      "ToRCH2014_E27_SEG.txt\n",
      "ToRCH2014_E28_SEG.txt\n",
      "ToRCH2014_E29A_SEG.txt\n",
      "ToRCH2014_E29B_SEG.txt\n",
      "ToRCH2014_E29C_SEG.txt\n",
      "ToRCH2014_E30A_SEG.txt\n",
      "ToRCH2014_E30B_SEG.txt\n",
      "ToRCH2014_E31A_SEG.txt\n",
      "ToRCH2014_E31B_SEG.txt\n",
      "ToRCH2014_E32A_SEG.txt\n",
      "ToRCH2014_E32B_SEG.txt\n",
      "ToRCH2014_E33_SEG.txt\n",
      "ToRCH2014_E34_SEG.txt\n",
      "ToRCH2014_E35A_SEG.txt\n",
      "ToRCH2014_E35B_SEG.txt\n",
      "ToRCH2014_E36A_SEG.txt\n",
      "ToRCH2014_E36B_SEG.txt\n",
      "ToRCH2014_E36C_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type E skills and hobbies\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_E*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_files=['ToRCH2014_E01_SEG.txt', 'ToRCH2014_E02_SEG.txt', 'ToRCH2014_E03_SEG.txt', 'ToRCH2014_E04A_SEG.txt', 'ToRCH2014_E04B_SEG.txt', 'ToRCH2014_E05A_SEG.txt', 'ToRCH2014_E05B_SEG.txt', 'ToRCH2014_E06_SEG.txt', 'ToRCH2014_E07A_SEG.txt', 'ToRCH2014_E07B_SEG.txt', 'ToRCH2014_E07C_SEG.txt', 'ToRCH2014_E08_SEG.txt', 'ToRCH2014_E09A_SEG.txt', 'ToRCH2014_E09B_SEG.txt', 'ToRCH2014_E09C_SEG.txt', 'ToRCH2014_E10A_SEG.txt', 'ToRCH2014_E10B_SEG.txt', 'ToRCH2014_E11A_SEG.txt', 'ToRCH2014_E11B_SEG.txt', 'ToRCH2014_E12A_SEG.txt', 'ToRCH2014_E12B_SEG.txt', 'ToRCH2014_E13A_SEG.txt', 'ToRCH2014_E13B_SEG.txt', 'ToRCH2014_E14A_SEG.txt', 'ToRCH2014_E14B_SEG.txt', 'ToRCH2014_E15A_SEG.txt', 'ToRCH2014_E15B_SEG.txt', 'ToRCH2014_E16_SEG.txt', 'ToRCH2014_E17A_SEG.txt', 'ToRCH2014_E17B_SEG.txt', 'ToRCH2014_E18A_SEG.txt', 'ToRCH2014_E18B_SEG.txt', 'ToRCH2014_E19A_SEG.txt', 'ToRCH2014_E19B_SEG.txt', 'ToRCH2014_E20A_SEG.txt', 'ToRCH2014_E20B_SEG.txt', 'ToRCH2014_E21_SEG.txt', 'ToRCH2014_E22A_SEG.txt', 'ToRCH2014_E22B_SEG.txt', 'ToRCH2014_E23_SEG.txt', 'ToRCH2014_E24_SEG.txt', 'ToRCH2014_E25_SEG.txt', 'ToRCH2014_E26_SEG.txt', 'ToRCH2014_E27_SEG.txt', 'ToRCH2014_E28_SEG.txt', 'ToRCH2014_E29A_SEG.txt', 'ToRCH2014_E29B_SEG.txt', 'ToRCH2014_E29C_SEG.txt', 'ToRCH2014_E30A_SEG.txt', 'ToRCH2014_E30B_SEG.txt', 'ToRCH2014_E31A_SEG.txt', 'ToRCH2014_E31B_SEG.txt', 'ToRCH2014_E32A_SEG.txt', 'ToRCH2014_E32B_SEG.txt', 'ToRCH2014_E33_SEG.txt', 'ToRCH2014_E34_SEG.txt', 'ToRCH2014_E35A_SEG.txt', 'ToRCH2014_E35B_SEG.txt', 'ToRCH2014_E36A_SEG.txt', 'ToRCH2014_E36B_SEG.txt', 'ToRCH2014_E36C_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills=corpus.words(skills_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_F01_SEG.txt\n",
      "ToRCH2014_F02_SEG.txt\n",
      "ToRCH2014_F03_SEG.txt\n",
      "ToRCH2014_F04_SEG.txt\n",
      "ToRCH2014_F05_SEG.txt\n",
      "ToRCH2014_F06_SEG.txt\n",
      "ToRCH2014_F07_SEG.txt\n",
      "ToRCH2014_F08_SEG.txt\n",
      "ToRCH2014_F09_SEG.txt\n",
      "ToRCH2014_F10_SEG.txt\n",
      "ToRCH2014_F11_SEG.txt\n",
      "ToRCH2014_F12_SEG.txt\n",
      "ToRCH2014_F13_SEG.txt\n",
      "ToRCH2014_F14_SEG.txt\n",
      "ToRCH2014_F15_SEG.txt\n",
      "ToRCH2014_F16_SEG.txt\n",
      "ToRCH2014_F17_SEG.txt\n",
      "ToRCH2014_F18_SEG.txt\n",
      "ToRCH2014_F19_SEG.txt\n",
      "ToRCH2014_F20_SEG.txt\n",
      "ToRCH2014_F21_SEG.txt\n",
      "ToRCH2014_F22_SEG.txt\n",
      "ToRCH2014_F23_SEG.txt\n",
      "ToRCH2014_F24_SEG.txt\n",
      "ToRCH2014_F25_SEG.txt\n",
      "ToRCH2014_F26_SEG.txt\n",
      "ToRCH2014_F27_SEG.txt\n",
      "ToRCH2014_F28_SEG.txt\n",
      "ToRCH2014_F29_SEG.txt\n",
      "ToRCH2014_F30_SEG.txt\n",
      "ToRCH2014_F31_SEG.txt\n",
      "ToRCH2014_F32_SEG.txt\n",
      "ToRCH2014_F33_SEG.txt\n",
      "ToRCH2014_F34_SEG.txt\n",
      "ToRCH2014_F35_SEG.txt\n",
      "ToRCH2014_F36_SEG.txt\n",
      "ToRCH2014_F37_SEG.txt\n",
      "ToRCH2014_F38_SEG.txt\n",
      "ToRCH2014_F39_SEG.txt\n",
      "ToRCH2014_F40_SEG.txt\n",
      "ToRCH2014_F41_SEG.txt\n",
      "ToRCH2014_F42_SEG.txt\n",
      "ToRCH2014_F43_SEG.txt\n",
      "ToRCH2014_F44_SEG.txt\n",
      "ToRCH2014_F45_SEG.txt\n",
      "ToRCH2014_F46_SEG.txt\n",
      "ToRCH2014_F47_SEG.txt\n",
      "ToRCH2014_F48_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type F popular lore\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_F*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_files=['ToRCH2014_F01_SEG.txt', 'ToRCH2014_F02_SEG.txt', 'ToRCH2014_F03_SEG.txt', 'ToRCH2014_F04_SEG.txt', 'ToRCH2014_F05_SEG.txt', 'ToRCH2014_F06_SEG.txt', 'ToRCH2014_F07_SEG.txt', 'ToRCH2014_F08_SEG.txt', 'ToRCH2014_F09_SEG.txt', 'ToRCH2014_F10_SEG.txt', 'ToRCH2014_F11_SEG.txt', 'ToRCH2014_F12_SEG.txt', 'ToRCH2014_F13_SEG.txt', 'ToRCH2014_F14_SEG.txt', 'ToRCH2014_F15_SEG.txt', 'ToRCH2014_F16_SEG.txt', 'ToRCH2014_F17_SEG.txt', 'ToRCH2014_F18_SEG.txt', 'ToRCH2014_F19_SEG.txt', 'ToRCH2014_F20_SEG.txt', 'ToRCH2014_F21_SEG.txt', 'ToRCH2014_F22_SEG.txt', 'ToRCH2014_F23_SEG.txt', 'ToRCH2014_F24_SEG.txt', 'ToRCH2014_F25_SEG.txt', 'ToRCH2014_F26_SEG.txt', 'ToRCH2014_F27_SEG.txt', 'ToRCH2014_F28_SEG.txt', 'ToRCH2014_F29_SEG.txt', 'ToRCH2014_F30_SEG.txt', 'ToRCH2014_F31_SEG.txt', 'ToRCH2014_F32_SEG.txt', 'ToRCH2014_F33_SEG.txt', 'ToRCH2014_F34_SEG.txt', 'ToRCH2014_F35_SEG.txt', 'ToRCH2014_F36_SEG.txt', 'ToRCH2014_F37_SEG.txt', 'ToRCH2014_F38_SEG.txt', 'ToRCH2014_F39_SEG.txt', 'ToRCH2014_F40_SEG.txt', 'ToRCH2014_F41_SEG.txt', 'ToRCH2014_F42_SEG.txt', 'ToRCH2014_F43_SEG.txt', 'ToRCH2014_F44_SEG.txt', 'ToRCH2014_F45_SEG.txt', 'ToRCH2014_F46_SEG.txt', 'ToRCH2014_F47_SEG.txt', 'ToRCH2014_F48_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular=corpus.words(popular_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_G01_SEG.txt\n",
      "ToRCH2014_G02_SEG.txt\n",
      "ToRCH2014_G03_SEG.txt\n",
      "ToRCH2014_G04_SEG.txt\n",
      "ToRCH2014_G05_SEG.txt\n",
      "ToRCH2014_G06_SEG.txt\n",
      "ToRCH2014_G07_SEG.txt\n",
      "ToRCH2014_G08_SEG.txt\n",
      "ToRCH2014_G09_SEG.txt\n",
      "ToRCH2014_G10_SEG.txt\n",
      "ToRCH2014_G11_SEG.txt\n",
      "ToRCH2014_G12_SEG.txt\n",
      "ToRCH2014_G13_SEG.txt\n",
      "ToRCH2014_G14_SEG.txt\n",
      "ToRCH2014_G15_SEG.txt\n",
      "ToRCH2014_G16_SEG.txt\n",
      "ToRCH2014_G17_SEG.txt\n",
      "ToRCH2014_G18_SEG.txt\n",
      "ToRCH2014_G19_SEG.txt\n",
      "ToRCH2014_G20_SEG.txt\n",
      "ToRCH2014_G21_SEG.txt\n",
      "ToRCH2014_G22_SEG.txt\n",
      "ToRCH2014_G23_SEG.txt\n",
      "ToRCH2014_G24_SEG.txt\n",
      "ToRCH2014_G25_SEG.txt\n",
      "ToRCH2014_G26_SEG.txt\n",
      "ToRCH2014_G27_SEG.txt\n",
      "ToRCH2014_G28_SEG.txt\n",
      "ToRCH2014_G29_SEG.txt\n",
      "ToRCH2014_G30_SEG.txt\n",
      "ToRCH2014_G31_SEG.txt\n",
      "ToRCH2014_G32_SEG.txt\n",
      "ToRCH2014_G33_SEG.txt\n",
      "ToRCH2014_G34_SEG.txt\n",
      "ToRCH2014_G35_SEG.txt\n",
      "ToRCH2014_G36_SEG.txt\n",
      "ToRCH2014_G37_SEG.txt\n",
      "ToRCH2014_G38_SEG.txt\n",
      "ToRCH2014_G39_SEG.txt\n",
      "ToRCH2014_G40_SEG.txt\n",
      "ToRCH2014_G41_SEG.txt\n",
      "ToRCH2014_G42_SEG.txt\n",
      "ToRCH2014_G43_SEG.txt\n",
      "ToRCH2014_G44_SEG.txt\n",
      "ToRCH2014_G45_SEG.txt\n",
      "ToRCH2014_G46_SEG.txt\n",
      "ToRCH2014_G47_SEG.txt\n",
      "ToRCH2014_G48_SEG.txt\n",
      "ToRCH2014_G49_SEG.txt\n",
      "ToRCH2014_G50_SEG.txt\n",
      "ToRCH2014_G51_SEG.txt\n",
      "ToRCH2014_G52_SEG.txt\n",
      "ToRCH2014_G53_SEG.txt\n",
      "ToRCH2014_G54_SEG.txt\n",
      "ToRCH2014_G55_SEG.txt\n",
      "ToRCH2014_G56_SEG.txt\n",
      "ToRCH2014_G57_SEG.txt\n",
      "ToRCH2014_G58_SEG.txt\n",
      "ToRCH2014_G59_SEG.txt\n",
      "ToRCH2014_G60_SEG.txt\n",
      "ToRCH2014_G61_SEG.txt\n",
      "ToRCH2014_G62_SEG.txt\n",
      "ToRCH2014_G63_SEG.txt\n",
      "ToRCH2014_G64_SEG.txt\n",
      "ToRCH2014_G65_SEG.txt\n",
      "ToRCH2014_G66_SEG.txt\n",
      "ToRCH2014_G67_SEG.txt\n",
      "ToRCH2014_G68_SEG.txt\n",
      "ToRCH2014_G69_SEG.txt\n",
      "ToRCH2014_G70_SEG.txt\n",
      "ToRCH2014_G71_SEG.txt\n",
      "ToRCH2014_G72_SEG.txt\n",
      "ToRCH2014_G73_SEG.txt\n",
      "ToRCH2014_G74_SEG.txt\n",
      "ToRCH2014_G75_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type G biographies\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_G*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "biography_files=['ToRCH2014_G01_SEG.txt', 'ToRCH2014_G02_SEG.txt', 'ToRCH2014_G03_SEG.txt', 'ToRCH2014_G04_SEG.txt', 'ToRCH2014_G05_SEG.txt', 'ToRCH2014_G06_SEG.txt', 'ToRCH2014_G07_SEG.txt', 'ToRCH2014_G08_SEG.txt', 'ToRCH2014_G09_SEG.txt', 'ToRCH2014_G10_SEG.txt', 'ToRCH2014_G11_SEG.txt', 'ToRCH2014_G12_SEG.txt', 'ToRCH2014_G13_SEG.txt', 'ToRCH2014_G14_SEG.txt', 'ToRCH2014_G15_SEG.txt', 'ToRCH2014_G16_SEG.txt', 'ToRCH2014_G17_SEG.txt', 'ToRCH2014_G18_SEG.txt', 'ToRCH2014_G19_SEG.txt', 'ToRCH2014_G20_SEG.txt', 'ToRCH2014_G21_SEG.txt', 'ToRCH2014_G22_SEG.txt', 'ToRCH2014_G23_SEG.txt', 'ToRCH2014_G24_SEG.txt', 'ToRCH2014_G25_SEG.txt', 'ToRCH2014_G26_SEG.txt', 'ToRCH2014_G27_SEG.txt', 'ToRCH2014_G28_SEG.txt', 'ToRCH2014_G29_SEG.txt', 'ToRCH2014_G30_SEG.txt', 'ToRCH2014_G31_SEG.txt', 'ToRCH2014_G32_SEG.txt', 'ToRCH2014_G33_SEG.txt', 'ToRCH2014_G34_SEG.txt', 'ToRCH2014_G35_SEG.txt', 'ToRCH2014_G36_SEG.txt', 'ToRCH2014_G37_SEG.txt', 'ToRCH2014_G38_SEG.txt', 'ToRCH2014_G39_SEG.txt', 'ToRCH2014_G40_SEG.txt', 'ToRCH2014_G41_SEG.txt', 'ToRCH2014_G42_SEG.txt', 'ToRCH2014_G43_SEG.txt', 'ToRCH2014_G44_SEG.txt', 'ToRCH2014_G45_SEG.txt', 'ToRCH2014_G46_SEG.txt', 'ToRCH2014_G47_SEG.txt', 'ToRCH2014_G48_SEG.txt', 'ToRCH2014_G49_SEG.txt', 'ToRCH2014_G50_SEG.txt', 'ToRCH2014_G51_SEG.txt', 'ToRCH2014_G52_SEG.txt', 'ToRCH2014_G53_SEG.txt', 'ToRCH2014_G54_SEG.txt', 'ToRCH2014_G55_SEG.txt', 'ToRCH2014_G56_SEG.txt', 'ToRCH2014_G57_SEG.txt', 'ToRCH2014_G58_SEG.txt', 'ToRCH2014_G59_SEG.txt', 'ToRCH2014_G60_SEG.txt', 'ToRCH2014_G61_SEG.txt', 'ToRCH2014_G62_SEG.txt', 'ToRCH2014_G63_SEG.txt', 'ToRCH2014_G64_SEG.txt', 'ToRCH2014_G65_SEG.txt', 'ToRCH2014_G66_SEG.txt', 'ToRCH2014_G67_SEG.txt', 'ToRCH2014_G68_SEG.txt', 'ToRCH2014_G69_SEG.txt', 'ToRCH2014_G70_SEG.txt', 'ToRCH2014_G71_SEG.txt', 'ToRCH2014_G72_SEG.txt', 'ToRCH2014_G73_SEG.txt', 'ToRCH2014_G74_SEG.txt', 'ToRCH2014_G75_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "biography=corpus.words(biography_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_H01_SEG.txt\n",
      "ToRCH2014_H02_SEG.txt\n",
      "ToRCH2014_H03_SEG.txt\n",
      "ToRCH2014_H04_SEG.txt\n",
      "ToRCH2014_H05_SEG.txt\n",
      "ToRCH2014_H06_SEG.txt\n",
      "ToRCH2014_H07_SEG.txt\n",
      "ToRCH2014_H08_SEG.txt\n",
      "ToRCH2014_H09_SEG.txt\n",
      "ToRCH2014_H10_SEG.txt\n",
      "ToRCH2014_H11_SEG.txt\n",
      "ToRCH2014_H12_SEG.txt\n",
      "ToRCH2014_H13_SEG.txt\n",
      "ToRCH2014_H14_SEG.txt\n",
      "ToRCH2014_H15_SEG.txt\n",
      "ToRCH2014_H16_SEG.txt\n",
      "ToRCH2014_H17_SEG.txt\n",
      "ToRCH2014_H18_SEG.txt\n",
      "ToRCH2014_H19_SEG.txt\n",
      "ToRCH2014_H20_SEG.txt\n",
      "ToRCH2014_H21_SEG.txt\n",
      "ToRCH2014_H22_SEG.txt\n",
      "ToRCH2014_H23_SEG.txt\n",
      "ToRCH2014_H24_SEG.txt\n",
      "ToRCH2014_H25_SEG.txt\n",
      "ToRCH2014_H26_SEG.txt\n",
      "ToRCH2014_H27_SEG.txt\n",
      "ToRCH2014_H28_SEG.txt\n",
      "ToRCH2014_H29_SEG.txt\n",
      "ToRCH2014_H30_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#file H official documents\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_H*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_files=['ToRCH2014_H01_SEG.txt', 'ToRCH2014_H02_SEG.txt', 'ToRCH2014_H03_SEG.txt', 'ToRCH2014_H04_SEG.txt', 'ToRCH2014_H05_SEG.txt', 'ToRCH2014_H06_SEG.txt', 'ToRCH2014_H07_SEG.txt', 'ToRCH2014_H08_SEG.txt', 'ToRCH2014_H09_SEG.txt', 'ToRCH2014_H10_SEG.txt', 'ToRCH2014_H11_SEG.txt', 'ToRCH2014_H12_SEG.txt', 'ToRCH2014_H13_SEG.txt', 'ToRCH2014_H14_SEG.txt', 'ToRCH2014_H15_SEG.txt', 'ToRCH2014_H16_SEG.txt', 'ToRCH2014_H17_SEG.txt', 'ToRCH2014_H18_SEG.txt', 'ToRCH2014_H19_SEG.txt', 'ToRCH2014_H20_SEG.txt', 'ToRCH2014_H21_SEG.txt', 'ToRCH2014_H22_SEG.txt', 'ToRCH2014_H23_SEG.txt', 'ToRCH2014_H24_SEG.txt', 'ToRCH2014_H25_SEG.txt', 'ToRCH2014_H26_SEG.txt', 'ToRCH2014_H27_SEG.txt', 'ToRCH2014_H28_SEG.txt', 'ToRCH2014_H29_SEG.txt', 'ToRCH2014_H30_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "official=corpus.words(official_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_J01_SEG.txt\n",
      "ToRCH2014_J02_SEG.txt\n",
      "ToRCH2014_J03_SEG.txt\n",
      "ToRCH2014_J04_SEG.txt\n",
      "ToRCH2014_J05_SEG.txt\n",
      "ToRCH2014_J06_SEG.txt\n",
      "ToRCH2014_J07_SEG.txt\n",
      "ToRCH2014_J08_SEG.txt\n",
      "ToRCH2014_J09_SEG.txt\n",
      "ToRCH2014_J10_SEG.txt\n",
      "ToRCH2014_J11_SEG.txt\n",
      "ToRCH2014_J12_SEG.txt\n",
      "ToRCH2014_J13_SEG.txt\n",
      "ToRCH2014_J14_SEG.txt\n",
      "ToRCH2014_J15_SEG.txt\n",
      "ToRCH2014_J16_SEG.txt\n",
      "ToRCH2014_J17_SEG.txt\n",
      "ToRCH2014_J18_SEG.txt\n",
      "ToRCH2014_J19_SEG.txt\n",
      "ToRCH2014_J20_SEG.txt\n",
      "ToRCH2014_J21_SEG.txt\n",
      "ToRCH2014_J22_SEG.txt\n",
      "ToRCH2014_J23_SEG.txt\n",
      "ToRCH2014_J24_SEG.txt\n",
      "ToRCH2014_J25_SEG.txt\n",
      "ToRCH2014_J26_SEG.txt\n",
      "ToRCH2014_J27_SEG.txt\n",
      "ToRCH2014_J28_SEG.txt\n",
      "ToRCH2014_J29_SEG.txt\n",
      "ToRCH2014_J30_SEG.txt\n",
      "ToRCH2014_J31_SEG.txt\n",
      "ToRCH2014_J32_SEG.txt\n",
      "ToRCH2014_J33_SEG.txt\n",
      "ToRCH2014_J34_SEG.txt\n",
      "ToRCH2014_J35_SEG.txt\n",
      "ToRCH2014_J36_SEG.txt\n",
      "ToRCH2014_J37_SEG.txt\n",
      "ToRCH2014_J38_SEG.txt\n",
      "ToRCH2014_J39_SEG.txt\n",
      "ToRCH2014_J40_SEG.txt\n",
      "ToRCH2014_J41_SEG.txt\n",
      "ToRCH2014_J42_SEG.txt\n",
      "ToRCH2014_J43_SEG.txt\n",
      "ToRCH2014_J44_SEG.txt\n",
      "ToRCH2014_J45_SEG.txt\n",
      "ToRCH2014_J46_SEG.txt\n",
      "ToRCH2014_J47_SEG.txt\n",
      "ToRCH2014_J48_SEG.txt\n",
      "ToRCH2014_J49_SEG.txt\n",
      "ToRCH2014_J50_SEG.txt\n",
      "ToRCH2014_J51_SEG.txt\n",
      "ToRCH2014_J52_SEG.txt\n",
      "ToRCH2014_J53_SEG.txt\n",
      "ToRCH2014_J54_SEG.txt\n",
      "ToRCH2014_J55_SEG.txt\n",
      "ToRCH2014_J56_SEG.txt\n",
      "ToRCH2014_J57_SEG.txt\n",
      "ToRCH2014_J58_SEG.txt\n",
      "ToRCH2014_J59_SEG.txt\n",
      "ToRCH2014_J60_SEG.txt\n",
      "ToRCH2014_J61_SEG.txt\n",
      "ToRCH2014_J62_SEG.txt\n",
      "ToRCH2014_J63_SEG.txt\n",
      "ToRCH2014_J64_SEG.txt\n",
      "ToRCH2014_J65_SEG.txt\n",
      "ToRCH2014_J66_SEG.txt\n",
      "ToRCH2014_J67_SEG.txt\n",
      "ToRCH2014_J68_SEG.txt\n",
      "ToRCH2014_J69_SEG.txt\n",
      "ToRCH2014_J70_SEG.txt\n",
      "ToRCH2014_J71_SEG.txt\n",
      "ToRCH2014_J72_SEG.txt\n",
      "ToRCH2014_J73_SEG.txt\n",
      "ToRCH2014_J74_SEG.txt\n",
      "ToRCH2014_J75_SEG.txt\n",
      "ToRCH2014_J76_SEG.txt\n",
      "ToRCH2014_J77_SEG.txt\n",
      "ToRCH2014_J78_SEG.txt\n",
      "ToRCH2014_J79_SEG.txt\n",
      "ToRCH2014_J80_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type J academic \n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_J*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_files=['ToRCH2014_J01_SEG.txt', 'ToRCH2014_J02_SEG.txt', 'ToRCH2014_J03_SEG.txt', 'ToRCH2014_J04_SEG.txt', 'ToRCH2014_J05_SEG.txt', 'ToRCH2014_J06_SEG.txt', 'ToRCH2014_J07_SEG.txt', 'ToRCH2014_J08_SEG.txt', 'ToRCH2014_J09_SEG.txt', 'ToRCH2014_J10_SEG.txt', 'ToRCH2014_J11_SEG.txt', 'ToRCH2014_J12_SEG.txt', 'ToRCH2014_J13_SEG.txt', 'ToRCH2014_J14_SEG.txt', 'ToRCH2014_J15_SEG.txt', 'ToRCH2014_J16_SEG.txt', 'ToRCH2014_J17_SEG.txt', 'ToRCH2014_J18_SEG.txt', 'ToRCH2014_J19_SEG.txt', 'ToRCH2014_J20_SEG.txt', 'ToRCH2014_J21_SEG.txt', 'ToRCH2014_J22_SEG.txt', 'ToRCH2014_J23_SEG.txt', 'ToRCH2014_J24_SEG.txt', 'ToRCH2014_J25_SEG.txt', 'ToRCH2014_J26_SEG.txt', 'ToRCH2014_J27_SEG.txt', 'ToRCH2014_J28_SEG.txt', 'ToRCH2014_J29_SEG.txt', 'ToRCH2014_J30_SEG.txt', 'ToRCH2014_J31_SEG.txt', 'ToRCH2014_J32_SEG.txt', 'ToRCH2014_J33_SEG.txt', 'ToRCH2014_J34_SEG.txt', 'ToRCH2014_J35_SEG.txt', 'ToRCH2014_J36_SEG.txt', 'ToRCH2014_J37_SEG.txt', 'ToRCH2014_J38_SEG.txt', 'ToRCH2014_J39_SEG.txt', 'ToRCH2014_J40_SEG.txt', 'ToRCH2014_J41_SEG.txt', 'ToRCH2014_J42_SEG.txt', 'ToRCH2014_J43_SEG.txt', 'ToRCH2014_J44_SEG.txt', 'ToRCH2014_J45_SEG.txt', 'ToRCH2014_J46_SEG.txt', 'ToRCH2014_J47_SEG.txt', 'ToRCH2014_J48_SEG.txt', 'ToRCH2014_J49_SEG.txt', 'ToRCH2014_J50_SEG.txt', 'ToRCH2014_J51_SEG.txt', 'ToRCH2014_J52_SEG.txt', 'ToRCH2014_J53_SEG.txt', 'ToRCH2014_J54_SEG.txt', 'ToRCH2014_J55_SEG.txt', 'ToRCH2014_J56_SEG.txt', 'ToRCH2014_J57_SEG.txt', 'ToRCH2014_J58_SEG.txt', 'ToRCH2014_J59_SEG.txt', 'ToRCH2014_J60_SEG.txt', 'ToRCH2014_J61_SEG.txt', 'ToRCH2014_J62_SEG.txt', 'ToRCH2014_J63_SEG.txt', 'ToRCH2014_J64_SEG.txt', 'ToRCH2014_J65_SEG.txt', 'ToRCH2014_J66_SEG.txt', 'ToRCH2014_J67_SEG.txt', 'ToRCH2014_J68_SEG.txt', 'ToRCH2014_J69_SEG.txt', 'ToRCH2014_J70_SEG.txt', 'ToRCH2014_J71_SEG.txt', 'ToRCH2014_J72_SEG.txt', 'ToRCH2014_J73_SEG.txt', 'ToRCH2014_J74_SEG.txt', 'ToRCH2014_J75_SEG.txt', 'ToRCH2014_J76_SEG.txt', 'ToRCH2014_J77_SEG.txt', 'ToRCH2014_J78_SEG.txt', 'ToRCH2014_J79_SEG.txt', 'ToRCH2014_J80_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "academic=corpus.words(academic_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_K01_SEG.txt\n",
      "ToRCH2014_K02_SEG.txt\n",
      "ToRCH2014_K03_SEG.txt\n",
      "ToRCH2014_K04_SEG.txt\n",
      "ToRCH2014_K05_SEG.txt\n",
      "ToRCH2014_K06_SEG.txt\n",
      "ToRCH2014_K07_SEG.txt\n",
      "ToRCH2014_K08_SEG.txt\n",
      "ToRCH2014_K09_SEG.txt\n",
      "ToRCH2014_K10_SEG.txt\n",
      "ToRCH2014_K11_SEG.txt\n",
      "ToRCH2014_K12_SEG.txt\n",
      "ToRCH2014_K13_SEG.txt\n",
      "ToRCH2014_K14_SEG.txt\n",
      "ToRCH2014_K15_SEG.txt\n",
      "ToRCH2014_K16_SEG.txt\n",
      "ToRCH2014_K17_SEG.txt\n",
      "ToRCH2014_K18_SEG.txt\n",
      "ToRCH2014_K19_SEG.txt\n",
      "ToRCH2014_K20_SEG.txt\n",
      "ToRCH2014_K21_SEG.txt\n",
      "ToRCH2014_K22_SEG.txt\n",
      "ToRCH2014_K23_SEG.txt\n",
      "ToRCH2014_K24_SEG.txt\n",
      "ToRCH2014_K25_SEG.txt\n",
      "ToRCH2014_K26_SEG.txt\n",
      "ToRCH2014_K27_SEG.txt\n",
      "ToRCH2014_K28_SEG.txt\n",
      "ToRCH2014_K29_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type K general fiction \n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_K*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_fiction_files=['ToRCH2014_K01_SEG.txt', 'ToRCH2014_K02_SEG.txt', 'ToRCH2014_K03_SEG.txt', 'ToRCH2014_K04_SEG.txt', 'ToRCH2014_K05_SEG.txt', 'ToRCH2014_K06_SEG.txt', 'ToRCH2014_K07_SEG.txt', 'ToRCH2014_K08_SEG.txt', 'ToRCH2014_K09_SEG.txt', 'ToRCH2014_K10_SEG.txt', 'ToRCH2014_K11_SEG.txt', 'ToRCH2014_K12_SEG.txt', 'ToRCH2014_K13_SEG.txt', 'ToRCH2014_K14_SEG.txt', 'ToRCH2014_K15_SEG.txt', 'ToRCH2014_K16_SEG.txt', 'ToRCH2014_K17_SEG.txt', 'ToRCH2014_K18_SEG.txt', 'ToRCH2014_K19_SEG.txt', 'ToRCH2014_K20_SEG.txt', 'ToRCH2014_K21_SEG.txt', 'ToRCH2014_K22_SEG.txt', 'ToRCH2014_K23_SEG.txt', 'ToRCH2014_K24_SEG.txt', 'ToRCH2014_K25_SEG.txt', 'ToRCH2014_K26_SEG.txt', 'ToRCH2014_K27_SEG.txt', 'ToRCH2014_K28_SEG.txt', 'ToRCH2014_K29_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_fiction=corpus.words(general_fiction_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_L01_SEG.txt\n",
      "ToRCH2014_L02_SEG.txt\n",
      "ToRCH2014_L03_SEG.txt\n",
      "ToRCH2014_L04_SEG.txt\n",
      "ToRCH2014_L05_SEG.txt\n",
      "ToRCH2014_L06_SEG.txt\n",
      "ToRCH2014_L07_SEG.txt\n",
      "ToRCH2014_L08_SEG.txt\n",
      "ToRCH2014_L09_SEG.txt\n",
      "ToRCH2014_L10_SEG.txt\n",
      "ToRCH2014_L11_SEG.txt\n",
      "ToRCH2014_L12_SEG.txt\n",
      "ToRCH2014_L13_SEG.txt\n",
      "ToRCH2014_L14_SEG.txt\n",
      "ToRCH2014_L15_SEG.txt\n",
      "ToRCH2014_L16_SEG.txt\n",
      "ToRCH2014_L17_SEG.txt\n",
      "ToRCH2014_L18_SEG.txt\n",
      "ToRCH2014_L19_SEG.txt\n",
      "ToRCH2014_L20_SEG.txt\n",
      "ToRCH2014_L21_SEG.txt\n",
      "ToRCH2014_L22_SEG.txt\n",
      "ToRCH2014_L23_SEG.txt\n",
      "ToRCH2014_L24_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type L mystery fiction\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_L*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_fiction_files=['ToRCH2014_L01_SEG.txt', 'ToRCH2014_L02_SEG.txt', 'ToRCH2014_L03_SEG.txt', 'ToRCH2014_L04_SEG.txt', 'ToRCH2014_L05_SEG.txt', 'ToRCH2014_L06_SEG.txt', 'ToRCH2014_L07_SEG.txt', 'ToRCH2014_L08_SEG.txt', 'ToRCH2014_L09_SEG.txt', 'ToRCH2014_L10_SEG.txt', 'ToRCH2014_L11_SEG.txt', 'ToRCH2014_L12_SEG.txt', 'ToRCH2014_L13_SEG.txt', 'ToRCH2014_L14_SEG.txt', 'ToRCH2014_L15_SEG.txt', 'ToRCH2014_L16_SEG.txt', 'ToRCH2014_L17_SEG.txt', 'ToRCH2014_L18_SEG.txt', 'ToRCH2014_L19_SEG.txt', 'ToRCH2014_L20_SEG.txt', 'ToRCH2014_L21_SEG.txt', 'ToRCH2014_L22_SEG.txt', 'ToRCH2014_L23_SEG.txt', 'ToRCH2014_L24_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_fiction=corpus.words(mystery_fiction_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_M01_SEG.txt\n",
      "ToRCH2014_M02_SEG.txt\n",
      "ToRCH2014_M03_SEG.txt\n",
      "ToRCH2014_M04_SEG.txt\n",
      "ToRCH2014_M05_SEG.txt\n",
      "ToRCH2014_M06_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type M science fiction\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_M*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_fi_files=['ToRCH2014_M01_SEG.txt',\n",
    "'ToRCH2014_M02_SEG.txt',\n",
    "'ToRCH2014_M03_SEG.txt',\n",
    "'ToRCH2014_M04_SEG.txt',\n",
    "'ToRCH2014_M05_SEG.txt',\n",
    "'ToRCH2014_M06_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_fi=corpus.words(sci_fi_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_N01_SEG.txt\n",
      "ToRCH2014_N02_SEG.txt\n",
      "ToRCH2014_N03_SEG.txt\n",
      "ToRCH2014_N04_SEG.txt\n",
      "ToRCH2014_N05_SEG.txt\n",
      "ToRCH2014_N06_SEG.txt\n",
      "ToRCH2014_N07_SEG.txt\n",
      "ToRCH2014_N08_SEG.txt\n",
      "ToRCH2014_N09_SEG.txt\n",
      "ToRCH2014_N10_SEG.txt\n",
      "ToRCH2014_N11_SEG.txt\n",
      "ToRCH2014_N12_SEG.txt\n",
      "ToRCH2014_N13_SEG.txt\n",
      "ToRCH2014_N14_SEG.txt\n",
      "ToRCH2014_N15_SEG.txt\n",
      "ToRCH2014_N16_SEG.txt\n",
      "ToRCH2014_N17_SEG.txt\n",
      "ToRCH2014_N18_SEG.txt\n",
      "ToRCH2014_N19_SEG.txt\n",
      "ToRCH2014_N20_SEG.txt\n",
      "ToRCH2014_N21_SEG.txt\n",
      "ToRCH2014_N22_SEG.txt\n",
      "ToRCH2014_N23_SEG.txt\n",
      "ToRCH2014_N24_SEG.txt\n",
      "ToRCH2014_N25_SEG.txt\n",
      "ToRCH2014_N26_SEG.txt\n",
      "ToRCH2014_N27_SEG.txt\n",
      "ToRCH2014_N28_SEG.txt\n",
      "ToRCH2014_N29_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type N adventure\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_N*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adventure_fiction_files=['ToRCH2014_N01_SEG.txt', 'ToRCH2014_N02_SEG.txt', 'ToRCH2014_N03_SEG.txt', 'ToRCH2014_N04_SEG.txt', 'ToRCH2014_N05_SEG.txt', 'ToRCH2014_N06_SEG.txt', 'ToRCH2014_N07_SEG.txt', 'ToRCH2014_N08_SEG.txt', 'ToRCH2014_N09_SEG.txt', 'ToRCH2014_N10_SEG.txt', 'ToRCH2014_N11_SEG.txt', 'ToRCH2014_N12_SEG.txt', 'ToRCH2014_N13_SEG.txt', 'ToRCH2014_N14_SEG.txt', 'ToRCH2014_N15_SEG.txt', 'ToRCH2014_N16_SEG.txt', 'ToRCH2014_N17_SEG.txt', 'ToRCH2014_N18_SEG.txt', 'ToRCH2014_N19_SEG.txt', 'ToRCH2014_N20_SEG.txt', 'ToRCH2014_N21_SEG.txt', 'ToRCH2014_N22_SEG.txt', 'ToRCH2014_N23_SEG.txt', 'ToRCH2014_N24_SEG.txt', 'ToRCH2014_N25_SEG.txt', 'ToRCH2014_N26_SEG.txt', 'ToRCH2014_N27_SEG.txt', 'ToRCH2014_N28_SEG.txt', 'ToRCH2014_N29_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adventure_fiction=corpus.words(adventure_fiction_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_P01_SEG.txt\n",
      "ToRCH2014_P02_SEG.txt\n",
      "ToRCH2014_P03_SEG.txt\n",
      "ToRCH2014_P04_SEG.txt\n",
      "ToRCH2014_P05_SEG.txt\n",
      "ToRCH2014_P06_SEG.txt\n",
      "ToRCH2014_P07_SEG.txt\n",
      "ToRCH2014_P08_SEG.txt\n",
      "ToRCH2014_P09_SEG.txt\n",
      "ToRCH2014_P10_SEG.txt\n",
      "ToRCH2014_P11_SEG.txt\n",
      "ToRCH2014_P12_SEG.txt\n",
      "ToRCH2014_P13_SEG.txt\n",
      "ToRCH2014_P14_SEG.txt\n",
      "ToRCH2014_P15_SEG.txt\n",
      "ToRCH2014_P16_SEG.txt\n",
      "ToRCH2014_P17_SEG.txt\n",
      "ToRCH2014_P18_SEG.txt\n",
      "ToRCH2014_P19_SEG.txt\n",
      "ToRCH2014_P20_SEG.txt\n",
      "ToRCH2014_P21_SEG.txt\n",
      "ToRCH2014_P22_SEG.txt\n",
      "ToRCH2014_P23_SEG.txt\n",
      "ToRCH2014_P24_SEG.txt\n",
      "ToRCH2014_P25_SEG.txt\n",
      "ToRCH2014_P26_SEG.txt\n",
      "ToRCH2014_P27_SEG.txt\n",
      "ToRCH2014_P28_SEG.txt\n",
      "ToRCH2014_P29_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type P romantic\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_P*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "romantic_fiction_files=['ToRCH2014_P01_SEG.txt', 'ToRCH2014_P02_SEG.txt', 'ToRCH2014_P03_SEG.txt', 'ToRCH2014_P04_SEG.txt', 'ToRCH2014_P05_SEG.txt', 'ToRCH2014_P06_SEG.txt', 'ToRCH2014_P07_SEG.txt', 'ToRCH2014_P08_SEG.txt', 'ToRCH2014_P09_SEG.txt', 'ToRCH2014_P10_SEG.txt', 'ToRCH2014_P11_SEG.txt', 'ToRCH2014_P12_SEG.txt', 'ToRCH2014_P13_SEG.txt', 'ToRCH2014_P14_SEG.txt', 'ToRCH2014_P15_SEG.txt', 'ToRCH2014_P16_SEG.txt', 'ToRCH2014_P17_SEG.txt', 'ToRCH2014_P18_SEG.txt', 'ToRCH2014_P19_SEG.txt', 'ToRCH2014_P20_SEG.txt', 'ToRCH2014_P21_SEG.txt', 'ToRCH2014_P22_SEG.txt', 'ToRCH2014_P23_SEG.txt', 'ToRCH2014_P24_SEG.txt', 'ToRCH2014_P25_SEG.txt', 'ToRCH2014_P26_SEG.txt', 'ToRCH2014_P27_SEG.txt', 'ToRCH2014_P28_SEG.txt', 'ToRCH2014_P29_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "romantic_fiction=corpus.words(romantic_fiction_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToRCH2014_R01_SEG.txt\n",
      "ToRCH2014_R02_SEG.txt\n",
      "ToRCH2014_R03_SEG.txt\n",
      "ToRCH2014_R04_SEG.txt\n",
      "ToRCH2014_R05_SEG.txt\n",
      "ToRCH2014_R06_SEG.txt\n",
      "ToRCH2014_R07_SEG.txt\n",
      "ToRCH2014_R08A_SEG.txt\n",
      "ToRCH2014_R08B_SEG.txt\n",
      "ToRCH2014_R09_SEG.txt\n"
     ]
    }
   ],
   "source": [
    "#type R humor\n",
    "for f in files: \n",
    "    if fnmatch.fnmatch(f, 'ToRCH2014_R*.txt'):\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "humor_files=['ToRCH2014_R01_SEG.txt', 'ToRCH2014_R02_SEG.txt', 'ToRCH2014_R03_SEG.txt', 'ToRCH2014_R04_SEG.txt', 'ToRCH2014_R05_SEG.txt', 'ToRCH2014_R06_SEG.txt', 'ToRCH2014_R07_SEG.txt', 'ToRCH2014_R08A_SEG.txt', 'ToRCH2014_R08B_SEG.txt', 'ToRCH2014_R09_SEG.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "humor=corpus.words(humor_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_type=[reportage, editorial, review, \\\n",
    "           religion, skills, popular, \\\n",
    "           biography, official, academic,\\\n",
    "           general_fiction, mystery_fiction, \n",
    "           sci_fi, adventure_fiction, \\\n",
    "           romantic_fiction, humor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003_OC_segmented.txt\n",
      "2004_OC_segmented.txt\n",
      "2005_OC_segmented.txt\n",
      "2006_OC_segmented.txt\n",
      "2007_OC_segmented.txt\n",
      "2013_OC_segmented.txt\n",
      "2014_OC_segmented.txt\n",
      "2015_OC_segmented.txt\n",
      "2016_OC_segmented.txt\n",
      "2017_OC_segmented.txt\n",
      "OC_segmented_we.txt\n",
      "total_OC_segmented.txt\n"
     ]
    }
   ],
   "source": [
    "#SCIPPC\n",
    "import fileinput\n",
    "\n",
    "files=corpus.fileids()\n",
    "\n",
    "for f in files:\n",
    "    print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OC_2003=corpus.words('2003_OC_segmented.txt')\n",
    "OC_2004=corpus.words('2004_OC_segmented.txt')\n",
    "OC_2005=corpus.words('2005_OC_segmented.txt')\n",
    "OC_2006=corpus.words('2006_OC_segmented.txt')\n",
    "OC_2007=corpus.words('2007_OC_segmented.txt')\n",
    "OC_2013=corpus.words('2013_OC_segmented.txt')\n",
    "OC_2014=corpus.words('2014_OC_segmented.txt')\n",
    "OC_2015=corpus.words('2015_OC_segmented.txt')\n",
    "OC_2016=corpus.words('2016_OC_segmented.txt')\n",
    "OC_2017=corpus.words('2017_OC_segmented.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OC_type=[OC_2003, OC_2004, OC_2005, OC_2006, OC_2007, \\\n",
    "         OC_2013, OC_2014, OC_2015, OC_2016, OC_2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106191\n",
      "66319\n",
      "40488\n",
      "41814\n",
      "89909\n",
      "128374\n",
      "180302\n",
      "72551\n",
      "191547\n",
      "70923\n",
      "58691\n",
      "14687\n",
      "69643\n",
      "70733\n",
      "22144\n"
     ]
    }
   ],
   "source": [
    "for text in text_type: \n",
    "    print (len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 1 \n",
    "#AMP amplifiers 非常、十分、真的、特别、很、最、肯定、挺、顶、极、\n",
    "#极为、极其、极度、万分、格外、分外、更、更加、更为、尤其、太、过于、\n",
    "#老、怪、相当、颇、颇为、有点儿、有些、最为、还、越发、越加、愈加、\n",
    "#稍、稍微、稍稍、略、略略、略微、比较、较、暴、超、恶、怒、巨、粉、奇\n",
    "def amplifiers(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('非常')+text_type.count('十分')+text_type.count('真的')+text_type.count('特别')+text_type.count('很')+text_type.count('最')+text_type.count('肯定')+text_type.count('挺')+text_type.count('顶')+text_type.count('极')+text_type.count('极为')+text_type.count('极其')+text_type.count('极度')+text_type.count('万分')+text_type.count('格外')+text_type.count('分外')+text_type.count('更')+text_type.count('更加')+text_type.count('更为')+text_type.count('尤其')+text_type.count('太')+text_type.count('过于')+text_type.count('老')+text_type.count('怪')+text_type.count('相当')+text_type.count('颇')+text_type.count('颇为')+text_type.count('有点儿')+text_type.count('有些')+text_type.count('最为')+text_type.count('还')+text_type.count('越发')+text_type.count('越加')+text_type.count('愈加')+text_type.count('稍')+text_type.count('稍微')+text_type.count('稍稍')+text_type.count('略')+text_type.count('略略')+text_type.count('略微')+text_type.count('比较')+text_type.count('较')+text_type.count('暴')+text_type.count('超')+text_type.count('恶')+text_type.count('怒')+text_type.count('巨')+text_type.count('粉')+text_type.count('奇')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.95\n",
      "10.64\n",
      "12.35\n",
      "13.72\n",
      "13.71\n",
      "14.22\n",
      "13.88\n",
      "16.29\n",
      "16.03\n",
      "12.94\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (amplifiers(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.19\n",
      "8.49\n",
      "8.74\n",
      "8.3\n",
      "10.91\n",
      "11.15\n",
      "11.81\n",
      "3.35\n",
      "7.4\n",
      "11.51\n",
      "12.49\n",
      "8.65\n",
      "11.21\n",
      "11.9\n",
      "12.42\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (amplifiers(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waiting for spoken corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 2 ANDC independent clause coordination\n",
    "#和、以及、而、与、并、以至、及、并且\n",
    "def andc(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('和')+text_type.count('以及')+text_type.count('而')+text_type.count('与')+text_type.count('并')+text_type.count('以至')+text_type.count('及')+text_type.count('并且')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.94\n",
      "16.34\n",
      "12.74\n",
      "18.07\n",
      "16.21\n",
      "12.07\n",
      "10.13\n",
      "10.72\n",
      "8.82\n",
      "7.98\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (andc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.13\n",
      "15.8\n",
      "19.39\n",
      "16.1\n",
      "15.22\n",
      "11.66\n",
      "12.22\n",
      "25.5\n",
      "26.99\n",
      "7.04\n",
      "6.27\n",
      "9.19\n",
      "7.29\n",
      "6.42\n",
      "4.61\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (andc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 3 word length AWL\n",
    "raw_reportage=corpus.raw(reportage_files)\n",
    "raw_editorial=corpus.raw(editorial_files)\n",
    "raw_review=corpus.raw(review_files)\n",
    "raw_religion=corpus.raw(religion_files)\n",
    "raw_skills=corpus.raw(skills_files)\n",
    "raw_popular=corpus.raw(popular_files)\n",
    "raw_biography=corpus.raw(biography_files)\n",
    "raw_official=corpus.raw(official_files)\n",
    "raw_academic=corpus.raw(academic_files)\n",
    "raw_general_fiction=corpus.raw(general_fiction_files)\n",
    "raw_mystery_fiction=corpus.raw(mystery_fiction_files)\n",
    "raw_sci_fi=corpus.raw(sci_fi_files)\n",
    "raw_adventure_fiction=corpus.raw(adventure_fiction_files)\n",
    "raw_romantic_fiction=corpus.raw(romantic_fiction_files)\n",
    "raw_humor=corpus.raw(humor_files)\n",
    "\n",
    "def awl(text_type): \n",
    "    words=text_type.split()\n",
    "    def average(words): \n",
    "        return sum(len(word) for word in words) / len(words)\n",
    "    return round(average(words), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 3 word length AWL\n",
    "raw_2003=corpus.raw('2003_OC_segmented.txt')\n",
    "raw_2004=corpus.raw('2004_OC_segmented.txt')\n",
    "raw_2005=corpus.raw('2005_OC_segmented.txt')\n",
    "raw_2006=corpus.raw('2006_OC_segmented.txt')\n",
    "raw_2007=corpus.raw('2007_OC_segmented.txt')\n",
    "raw_2013=corpus.raw('2013_OC_segmented.txt')\n",
    "raw_2014=corpus.raw('2014_OC_segmented.txt')\n",
    "raw_2015=corpus.raw('2015_OC_segmented.txt')\n",
    "raw_2016=corpus.raw('2016_OC_segmented.txt')\n",
    "raw_2017=corpus.raw('2017_OC_segmented.txt')\n",
    "\n",
    "def awl(text_type): \n",
    "    words=text_type.split()\n",
    "    def average(words): \n",
    "        return sum(len(word) for word in words) / len(words)\n",
    "    return round(average(words), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_type=[raw_2003, raw_2004, raw_2005, raw_2006, raw_2007, \\\n",
    "         raw_2013, raw_2014, raw_2015, raw_2016, raw_2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_type=[raw_reportage, raw_editorial, raw_review, \\\n",
    "           raw_religion, raw_skills, raw_popular, \\\n",
    "           raw_biography, raw_official, raw_academic,\\\n",
    "           raw_general_fiction, raw_mystery_fiction, \n",
    "           raw_sci_fi, raw_adventure_fiction, \\\n",
    "           raw_romantic_fiction, raw_humor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.57\n",
      "1.54\n",
      "1.54\n",
      "1.55\n",
      "1.56\n",
      "1.49\n",
      "1.52\n",
      "1.5\n",
      "1.51\n",
      "1.51\n"
     ]
    }
   ],
   "source": [
    "for text in raw_type:\n",
    "    print (awl(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.64\n",
      "1.63\n",
      "1.59\n",
      "1.44\n",
      "1.56\n",
      "1.47\n",
      "1.46\n",
      "1.73\n",
      "1.65\n",
      "1.41\n",
      "1.36\n",
      "1.44\n",
      "1.37\n",
      "1.39\n",
      "1.41\n"
     ]
    }
   ],
   "source": [
    "for text in raw_text_type:\n",
    "    print (awl(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caus(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('因为')+text_type.count('固')+text_type.count('所以')+text_type.count('则')+text_type.count('从而')+text_type.count('故')+text_type.count('结果')+text_type.count('所以')+text_type.count('为此')+text_type.count('以至')+text_type.count('以至于')+text_type.count('因')+text_type.count('因此')+text_type.count('因而')+text_type.count('由于')+text_type.count('于是')+text_type.count('之所以')+text_type.count('致使')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n",
      "3.42\n",
      "3.47\n",
      "3.47\n",
      "1.66\n",
      "3.64\n",
      "4.41\n",
      "5.28\n",
      "5.97\n",
      "4.72\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type:\n",
    "    print (caus(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.09"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature 6 CAUS 因果连词\n",
    "#因为、固、所以、则、从而、故、结果、所以、为此、以至、以至于、因、因此、因而、由于、于是、之所以、致使\n",
    "reportage_CAUS_raw=reportage.count('因为')+reportage.count('固')+reportage.count('所以')+reportage.count('则')+reportage.count('从而')+reportage.count('故')+reportage.count('结果')+reportage.count('所以')+reportage.count('为此')+reportage.count('以至')+reportage.count('以至于')+reportage.count('因')+reportage.count('因此')+reportage.count('因而')+reportage.count('由于')+reportage.count('于是')+reportage.count('之所以')+reportage.count('致使')\n",
    "reportage_CAUS_normalized=reportage_CAUS_raw / len(reportage)\n",
    "round (reportage_CAUS_normalized * 1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature 7 CONC 让步连词、副词\n",
    "#纵然、即使、虽然、虽说、固然、尽管\n",
    "reportage_CONC_raw=reportage.count('纵然')+reportage.count('即使')+reportage.count('虽然')+reportage.count('虽说')+reportage.count('固然')+reportage.count('尽管')\n",
    "reportage_CONC_normalized=reportage_CONC_raw / len(reportage)\n",
    "round (reportage_CONC_normalized * 1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conc(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('纵然')+text_type.count('即使')+text_type.count('虽然')+text_type.count('虽说')+text_type.count('固然')+text_type.count('尽管')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36\n",
      "0.38\n",
      "1.16\n",
      "0.69\n",
      "1.45\n",
      "0.33\n",
      "0.16\n",
      "0.15\n",
      "0.25\n",
      "0.36\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type:\n",
    "    print (conc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 8 COND 条件连词、副词\n",
    "#如果……（那么）、只有……（才）、假如、除非、要是、要不是、只要、假使、假如、倘若、倘或、倘、设使、设若、如若、若\n",
    "def cond(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('如果')+text_type.count('只有')+text_type.count('假如')+text_type.count('除非')+text_type.count('要是')+text_type.count('要不是')+text_type.count('只要')+text_type.count('假如')+text_type.count('倘若')+text_type.count('倘或')+text_type.count('设使')+text_type.count('设若')+text_type.count('如若')+text_type.count('若')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35\n",
      "1.33\n",
      "1.35\n",
      "1.91\n",
      "1.45\n",
      "1.32\n",
      "1.63\n",
      "1.61\n",
      "1.37\n",
      "1.33\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type:\n",
    "    print (cond(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.07"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature 9 CONJ and OSUB 连词、连接副词\n",
    "#换句话说、总的来说、一来、总之、继而、非但、而后、尔后、但是、但、同时、与此同时、并且、此外、那、那么、不过、只要、只有、只是、才、另外、甚至、而是、一方面、另一方面、就是说、无论是、以、然、首先、其次、再次、最后、综上所述、可是、或者、甚或、不仅、否则、既、既然、这就是说、不管、要是、接着、然后、换言之\n",
    "def conj(text_type): \n",
    "    def raw(text_type): \n",
    "        return text_type.count('换句话说')+text_type.count('总的来说')+text_type.count('一来')+text_type.count('总之')+text_type.count('继而')+text_type.count('非但')+text_type.count('而后')+text_type.count('尔后')+text_type.count('但是')+text_type.count('但')+text_type.count('同时')+text_type.count('与此同时')+text_type.count('并且')+text_type.count('此外')+text_type.count('那')+text_type.count('那么')+text_type.count('不过')+text_type.count('只要')+text_type.count('只有')+text_type.count('只是')+text_type.count('才')+text_type.count('另外')+text_type.count('甚至')+text_type.count('而是')+text_type.count('一方面')+text_type.count('另一方面')+text_type.count('就是说')+text_type.count('无论是')+text_type.count('以')+text_type.count('然')+text_type.count('首先')+text_type.count('其次')+text_type.count('再次')+text_type.count('最后')+text_type.count('综上所述')+text_type.count('可是')+text_type.count('或者')+text_type.count('甚或')+text_type.count('不仅')+text_type.count('否则')+text_type.count('既')+text_type.count('既然')+text_type.count('这就是说')+text_type.count('不管')+text_type.count('要是')+text_type.count('接着')+text_type.count('然后')+text_type.count('换言之')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.03\n",
      "12.35\n",
      "14.67\n",
      "13.03\n",
      "12.05\n",
      "12.23\n",
      "14.05\n",
      "12.92\n",
      "14.42\n",
      "11.97\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type:\n",
    "    print (conj(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 12 DPAR discourse markers\n",
    "#我跟你说、你知道吗、我告诉你、我跟你讲、你知道\n",
    "#不好意思、就这样、无所谓、没问题、不得了、不用说、不怎么、不怎么样、对了、好了、你看、罢了、话说回来、不要说、要说、算了、就是了、不像话、不要紧、没事儿、再说吧、巴不得、怪不得、就得了、得了、你说呢、说真的、没劲、没什么、有的是、怎么搞的、话是这么说、说不好、说了算、要我说、一句话、本来嘛、别看、够朋友、说白了\n",
    "def dpar(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('我 跟 你 说')+text_type.count('你 知道 吗')+text_type.count('我 告诉 你')+text_type.count('我 跟 你 讲')+text_type.count('你 知道')+text_type.count('不好意思')+text_type.count('就这样')+text_type.count('无所谓')+text_type.count('没问题')+text_type.count('不得了')+text_type.count('不用说')+text_type.count('不怎么')+text_type.count('不怎么样')+text_type.count('对了')+text_type.count('好了')+text_type.count('你看')+text_type.count('罢了')+text_type.count('话说回来')+text_type.count('不要说')+text_type.count('要说')+text_type.count('算了')+text_type.count('就是了')+text_type.count('不像话')+text_type.count('不要紧')+text_type.count('没事儿')+text_type.count('再说吧')+text_type.count('巴不得')+text_type.count('怪不得')+text_type.count('就得了')+text_type.count('得了')+text_type.count('你说呢')+text_type.count('说真的')+text_type.count('没劲')+text_type.count('没什么')+text_type.count('有的是')+text_type.count('怎么搞的')+text_type.count('话是这么说')+text_type.count('说不好')+text_type.count('说了算')+text_type.count('要我说')+text_type.count('一句话')+text_type.count('本来嘛')+text_type.count('别看')+text_type.count('够朋友')+text_type.count('说白了')\n",
    "\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.17\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.15\n",
      "0.0\n",
      "0.12\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type:\n",
    "    print (dpar(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06\n",
      "0.21\n",
      "0.1\n",
      "0.31\n",
      "0.12\n",
      "0.46\n",
      "0.21\n",
      "0.0\n",
      "0.01\n",
      "0.63\n",
      "0.29\n",
      "0.41\n",
      "0.33\n",
      "0.66\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "for text in text_type: \n",
    "    print (dpar(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 13 downtoners DWNT\n",
    "#一点、有点、有点儿、稍、稍微、一些、有些\n",
    "def dwnt(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('一点')+text_type.count('有点')+text_type.count('有点儿')+text_type.count('稍')+text_type.count('稍微')+text_type.count('一些')+text_type.count('有些')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63\n",
      "1.52\n",
      "0.97\n",
      "2.78\n",
      "0.83\n",
      "0.99\n",
      "3.92\n",
      "2.2\n",
      "3.73\n",
      "3.02\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (dwnt(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n",
      "1.91\n",
      "1.06\n",
      "1.34\n",
      "1.75\n",
      "1.43\n",
      "1.2\n",
      "0.18\n",
      "0.53\n",
      "1.55\n",
      "1.43\n",
      "1.09\n",
      "1.55\n",
      "1.72\n",
      "1.08\n"
     ]
    }
   ],
   "source": [
    "for text in text_type: \n",
    "    print (dwnt(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 14 emphatics EMPH\n",
    "#很大、相当、完全、显著、总是、根本\n",
    "def emph(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('很大')+text_type.count('相当')+text_type.count('完全')+text_type.count('显著')+text_type.count('总是')+text_type.count('根本')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99\n",
      "1.33\n",
      "1.54\n",
      "0.87\n",
      "0.62\n",
      "0.66\n",
      "0.16\n",
      "0.29\n",
      "0.5\n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (emph(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53\n",
      "0.72\n",
      "0.79\n",
      "0.6\n",
      "0.53\n",
      "0.75\n",
      "0.88\n",
      "0.23\n",
      "1.27\n",
      "1.0\n",
      "0.73\n",
      "0.68\n",
      "0.79\n",
      "0.9\n",
      "0.54\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (emph(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 16 FPP1 first person pronoun\n",
    "#我、我的、我自己、我们、我们自己、我们的\n",
    "#only 我 and 我们 are needed\n",
    "def fpp1(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('我')+text_type.count('我们')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.25\n",
      "28.88\n",
      "25.28\n",
      "21.54\n",
      "25.35\n",
      "23.47\n",
      "24.33\n",
      "23.05\n",
      "23.12\n",
      "24.91\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (fpp1(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.56\n",
      "3.6\n",
      "4.74\n",
      "7.49\n",
      "2.51\n",
      "14.8\n",
      "12.3\n",
      "1.79\n",
      "1.27\n",
      "17.44\n",
      "12.17\n",
      "10.28\n",
      "10.88\n",
      "15.61\n",
      "26.15\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (fpp1(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 17 hedges HDG\n",
    "#可能、可以、也许、较少、一些、多个、多为、基本、主要、类似、不少\n",
    "def hdg(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('可能')+text_type.count('可以')+text_type.count('也许')+text_type.count('较少')+text_type.count('一些')+text_type.count('多个')+text_type.count('多为')+text_type.count('基本')+text_type.count('主要')+text_type.count('类似')+text_type.count('不少')\n",
    "\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.08\n",
      "3.61\n",
      "4.83\n",
      "3.65\n",
      "2.08\n",
      "8.27\n",
      "10.78\n",
      "5.87\n",
      "10.56\n",
      "7.13\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (hdg(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07\n",
      "4.31\n",
      "3.38\n",
      "2.94\n",
      "6.34\n",
      "3.69\n",
      "2.86\n",
      "3.1\n",
      "4.9\n",
      "2.43\n",
      "2.33\n",
      "1.97\n",
      "2.17\n",
      "1.7\n",
      "2.44\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (hdg(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 18 INPR indefinite pronouns 无定代词\n",
    "#任何、谁、大家、某、有人、有个、什么\n",
    "def inpr(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('任何')+text_type.count('谁')+text_type.count('大家')+text_type.count('某')+text_type.count('有人')+text_type.count('有个')+text_type.count('什么')\n",
    "\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35\n",
      "4.94\n",
      "4.44\n",
      "5.39\n",
      "5.4\n",
      "2.98\n",
      "3.27\n",
      "2.35\n",
      "3.36\n",
      "3.14\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (inpr(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08 1.81 1.83 2.08 1.13 3.44 2.31 0.28 0.87 3.86 4.17 3.47 3.07 3.7 4.88 "
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (inpr(text), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 20 NEMD necessity modals 道义情态动词\n",
    "#能、应该、要、必须、得、必得、应当、该\n",
    "def nemd(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('能')+text_type.count('应该')+text_type.count('要')+text_type.count('必须')+text_type.count('得')+text_type.count('必得')+text_type.count('应当')+text_type.count('该')\n",
    "\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.87\n",
      "9.88\n",
      "7.53\n",
      "11.47\n",
      "11.01\n",
      "14.38\n",
      "16.17\n",
      "11.89\n",
      "13.42\n",
      "10.64\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (nemd(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53\n",
      "6.09\n",
      "5.09\n",
      "7.01\n",
      "8.86\n",
      "7.43\n",
      "6.63\n",
      "5.29\n",
      "5.63\n",
      "8.22\n",
      "7.99\n",
      "4.9\n",
      "7.67\n",
      "7.15\n",
      "8.58\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (nemd(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 21 knowledge modal verbs KNMD, cf. possibility modals in Biber 1988\n",
    "#可能、会、可以\n",
    "def knmd(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('可能')+text_type.count('会')+text_type.count('可以')\n",
    "\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.98\n",
      "6.27\n",
      "5.98\n",
      "5.21\n",
      "2.29\n",
      "9.75\n",
      "8.0\n",
      "9.69\n",
      "11.56\n",
      "9.55\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (knmd(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21\n",
      "3.83\n",
      "2.57\n",
      "3.66\n",
      "6.75\n",
      "5.33\n",
      "4.02\n",
      "1.19\n",
      "3.52\n",
      "3.68\n",
      "4.62\n",
      "4.77\n",
      "3.65\n",
      "3.48\n",
      "3.48\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (knmd(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 22 motivation modals 动力情态动词\n",
    "#能、敢、肯、要、愿意、能够\n",
    "def momd(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('能')+text_type.count('敢')+text_type.count('肯')+text_type.count('要')+text_type.count('愿意')+text_type.count('能够')\n",
    "\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.33\n",
      "8.17\n",
      "8.11\n",
      "9.56\n",
      "10.6\n",
      "13.89\n",
      "15.68\n",
      "12.18\n",
      "13.3\n",
      "11.49\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (momd(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32\n",
      "4.37\n",
      "3.14\n",
      "5.55\n",
      "7.66\n",
      "4.88\n",
      "4.59\n",
      "3.58\n",
      "3.47\n",
      "4.81\n",
      "4.92\n",
      "3.0\n",
      "4.87\n",
      "4.26\n",
      "4.61\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (momd(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 25 SPP2 second person pronoun\n",
    "#你、你们\n",
    "def spp2(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('你')+text_type.count('你们')\n",
    "\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.08\n",
      "1.52\n",
      "3.86\n",
      "3.47\n",
      "3.74\n",
      "2.98\n",
      "3.76\n",
      "4.55\n",
      "4.23\n",
      "3.39\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (spp2(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33\n",
      "0.56\n",
      "1.21\n",
      "2.65\n",
      "1.69\n",
      "6.23\n",
      "2.67\n",
      "0.07\n",
      "0.03\n",
      "7.4\n",
      "6.2\n",
      "4.83\n",
      "6.25\n",
      "7.93\n",
      "15.76\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (spp2(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 28 disyllabic propositions plus abstract nouns \n",
    "#BPIN 双音介词+抽象名词\n",
    "#按着、按照、本着、朝着、趁着、出于、待到、对于、根据、关于、基于、鉴于、借着\n",
    "#经过、靠着、冒着、面对、面临、凭借、顺着、随着、通过、为了、围绕、向着、沿着\n",
    "#依据、针对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpin_list=['按着', '按照', '本着', '朝着', '趁着', '出于',\\\n",
    "           '待到', '对于', '根据', '关于', '基于', '鉴于',\\\n",
    "           '借着', '经过', '靠着', '冒着', '面对', '面临', \\\n",
    "           '凭借', '顺着', '随着', '通过', '为了', '围绕',\\\n",
    "           '向着', '沿着', '依据', '针对']\n",
    "#for x in bpin_list: \n",
    "    #academic_text.concordance(x, width=100, lines=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 34 SMP seem, appear\n",
    "#好像、似乎、好象、貌似\n",
    "def smp(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('好象')+text_type.count('好像')\\\n",
    "    +text_type.count('似乎')+text_type.count('貌似')\n",
    "\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12\n",
      "0.12\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (smp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.2\n",
      "0.2\n",
      "0.22\n",
      "0.07\n",
      "0.58\n",
      "0.29\n",
      "0.0\n",
      "0.13\n",
      "0.56\n",
      "0.66\n",
      "0.61\n",
      "0.78\n",
      "0.86\n",
      "0.23\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (smp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 38 SMP seem, appear\n",
    "#好像、似乎、好象、貌似\n",
    "def tpp3(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('她')+text_type.count('他')\\\n",
    "    +text_type.count('它')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63\n",
      "1.71\n",
      "0.97\n",
      "1.04\n",
      "2.29\n",
      "1.49\n",
      "1.14\n",
      "2.35\n",
      "1.74\n",
      "1.93\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (tpp3(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.48\n",
      "1.22\n",
      "5.95\n",
      "5.07\n",
      "1.25\n",
      "13.39\n",
      "16.15\n",
      "0.01\n",
      "2.06\n",
      "20.26\n",
      "16.15\n",
      "22.06\n",
      "13.07\n",
      "23.06\n",
      "10.88\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (tpp3(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 39 TTR\n",
    "def sttr(text_type): \n",
    "    def ttr(text_type): \n",
    "        return (len(set(text_type)) / len(text_type)) * 1000\n",
    "    return round (ttr(text_type), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.95\n",
      "243.78\n",
      "236.44\n",
      "241.66\n",
      "259.71\n",
      "243.18\n",
      "247.1\n",
      "230.62\n",
      "202.71\n",
      "202.78\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (sttr(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.21\n",
      "146.44\n",
      "183.24\n",
      "164.71\n",
      "112.79\n",
      "126.03\n",
      "109.36\n",
      "90.38\n",
      "70.11\n",
      "144.3\n",
      "145.9\n",
      "265.06\n",
      "147.93\n",
      "142.99\n",
      "198.97\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (sttr(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 44 disyllabic words \n",
    "def disyllabic(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('购买')+text_type.count('具有')+text_type.count('在于')+text_type.count('寻找')+text_type.count('获得')+text_type.count('询问')+text_type.count('进入')+text_type.count('等候')+text_type.count('安定')+text_type.count('安装')+text_type.count('办理')+text_type.count('保持')+text_type.count('保留')+text_type.count('保卫')+text_type.count('保障')+text_type.count('报道')+text_type.count('暴露')+text_type.count('爆发')+text_type.count('被迫')+text_type.count('必然')+text_type.count('必修')+text_type.count('必要')+text_type.count('避免')+text_type.count('编制')+text_type.count('变动')+text_type.count('变革')+text_type.count('辩论')+text_type.count('表达')+text_type.count('表示')+text_type.count('表演')+text_type.count('并肩')+text_type.count('补习')+text_type.count('不断')+text_type.count('不时')+text_type.count('不住')+text_type.count('布置')+text_type.count('采取')+text_type.count('采用')+text_type.count('参考')+text_type.count('测量')+text_type.count('测试')+text_type.count('测验')+text_type.count('颤动')+text_type.count('抄写')+text_type.count('陈列')+text_type.count('成立')+text_type.count('成为')+text_type.count('承担')+text_type.count('承认')+text_type.count('持枪')+text_type.count('充分')+text_type.count('充满')+text_type.count('充实')+text_type.count('仇恨')+text_type.count('出版')+text_type.count('处于')+text_type.count('处处')+text_type.count('传播')+text_type.count('传达')+text_type.count('创立')+text_type.count('次要')+text_type.count('匆忙')+text_type.count('从容')+text_type.count('从事')+text_type.count('促进')+text_type.count('摧毁')+text_type.count('达成')+text_type.count('达到')+text_type.count('打扫')+text_type.count('大力')+text_type.count('大有')+text_type.count('担任')+text_type.count('导致')+text_type.count('到达')+text_type.count('等待')+text_type.count('等候')+text_type.count('奠定')+text_type.count('雕刻')+text_type.count('调查')+text_type.count('动员')+text_type.count('独自')+text_type.count('端正')+text_type.count('锻炼')+text_type.count('夺取')+text_type.count('发表')+text_type.count('发动')+text_type.count('发挥')+text_type.count('发射')+text_type.count('发生')+text_type.count('发行')+text_type.count('发扬')+text_type.count('发展')+text_type.count('反抗')+text_type.count('防守')+text_type.count('防御')+text_type.count('防止')+text_type.count('防治')+text_type.count('非法')+text_type.count('废除')+text_type.count('粉碎')+text_type.count('丰富')+text_type.count('封锁')+text_type.count('符合')+text_type.count('负担')+text_type.count('负责')+text_type.count('复述')+text_type.count('复习')+text_type.count('复印')+text_type.count('复杂')+text_type.count('复制')+text_type.count('富有')+text_type.count('改编')+text_type.count('改革')+text_type.count('改进')+text_type.count('改良')+text_type.count('改善')+text_type.count('改正')+text_type.count('干涉')+text_type.count('敢于')+text_type.count('高大')+text_type.count('高度')+text_type.count('高速')+text_type.count('格外')+text_type.count('给以')+text_type.count('更加')+text_type.count('公开')+text_type.count('公然')+text_type.count('巩固')+text_type.count('贡献')+text_type.count('共同')+text_type.count('构成')+text_type.count('购买')+text_type.count('观测')+text_type.count('观察')+text_type.count('观看')+text_type.count('贯彻')+text_type.count('灌溉')+text_type.count('光临')+text_type.count('规划')+text_type.count('合成')+text_type.count('合法')+text_type.count('宏伟')+text_type.count('缓和')+text_type.count('缓缓')+text_type.count('回答')+text_type.count('汇报')+text_type.count('混淆')+text_type.count('活跃')+text_type.count('获得')+text_type.count('基本')+text_type.count('集合')+text_type.count('集中')+text_type.count('极为')+text_type.count('即将')+text_type.count('计划')+text_type.count('记载')+text_type.count('继承')+text_type.count('加工')+text_type.count('加紧')+text_type.count('加速')+text_type.count('加以')+text_type.count('驾驶')+text_type.count('歼灭')+text_type.count('坚定')+text_type.count('减轻')+text_type.count('检验')+text_type.count('简直')+text_type.count('建立')+text_type.count('建造')+text_type.count('建筑')+text_type.count('交换')+text_type.count('交流')+text_type.count('结束')+text_type.count('竭力')+text_type.count('解决')+text_type.count('解释')+text_type.count('紧急')+text_type.count('紧密')+text_type.count('谨慎')+text_type.count('进军')+text_type.count('进攻')+text_type.count('进入')+text_type.count('进行')+text_type.count('尽力')+text_type.count('禁止')+text_type.count('精彩')+text_type.count('进过')+text_type.count('经历')+text_type.count('经受')+text_type.count('经营')+text_type.count('竞争')+text_type.count('竟然')+text_type.count('纠正')+text_type.count('举办')+text_type.count('举行')+text_type.count('具备')+text_type.count('具体')+text_type.count('具有')+text_type.count('开办')+text_type.count('开动')+text_type.count('开发')+text_type.count('开明')+text_type.count('开辟')+text_type.count('开枪')+text_type.count('开设')+text_type.count('开展')+text_type.count('抗议')+text_type.count('克服')+text_type.count('刻苦')+text_type.count('空前')+text_type.count('扩大')+text_type.count('来自')+text_type.count('滥用')+text_type.count('朗读')+text_type.count('力求')+text_type.count('力争')+text_type.count('连接')+text_type.count('列举')+text_type.count('流传')+text_type.count('垄断')+text_type.count('笼罩')+text_type.count('轮流')+text_type.count('掠夺')+text_type.count('满腔')+text_type.count('盲目')+text_type.count('猛烈')+text_type.count('猛然')+text_type.count('梦想')+text_type.count('勉强')+text_type.count('面临')+text_type.count('明明')+text_type.count('明确')+text_type.count('难以')+text_type.count('扭转')+text_type.count('拍摄')+text_type.count('排列')+text_type.count('攀登')+text_type.count('炮打')+text_type.count('赔偿')+text_type.count('评价')+text_type.count('评论')+text_type.count('赔偿')+text_type.count('评价')+text_type.count('评论')+text_type.count('破坏')+text_type.count('普遍')+text_type.count('普及')+text_type.count('起源')+text_type.count('签订')+text_type.count('强调')+text_type.count('抢夺')+text_type.count('切实')+text_type.count('侵略')+text_type.count('侵入')+text_type.count('轻易')+text_type.count('取得')+text_type.count('全部')+text_type.count('全面')+text_type.count('燃烧')+text_type.count('热爱')+text_type.count('忍受')+text_type.count('仍旧')+text_type.count('日益')+text_type.count('如同')+text_type.count('散布')+text_type.count('丧失')+text_type.count('设法')+text_type.count('设立')+text_type.count('实施')+text_type.count('实现')+text_type.count('实行')+text_type.count('实验')+text_type.count('适合')+text_type.count('试验')+text_type.count('收集')+text_type.count('收缩')+text_type.count('树立')+text_type.count('束缚')+text_type.count('思考')+text_type.count('思念')+text_type.count('思索')+text_type.count('丝毫')+text_type.count('四处')+text_type.count('饲养')+text_type.count('损害')+text_type.count('损坏')+text_type.count('损失')+text_type.count('缩短')+text_type.count('缩小')+text_type.count('贪图')+text_type.count('谈论')+text_type.count('探索')+text_type.count('逃避')+text_type.count('提倡')+text_type.count('提供')+text_type.count('提前')+text_type.count('体现')+text_type.count('调节')+text_type.count('调整')+text_type.count('停止')+text_type.count('统一')+text_type.count('突破')+text_type.count('推迟')+text_type.count('推动')+text_type.count('推进')+text_type.count('脱离')+text_type.count('歪曲')+text_type.count('完善')+text_type.count('万分')+text_type.count('万万')+text_type.count('危害')+text_type.count('违背')+text_type.count('违反')+text_type.count('维持')+text_type.count('维护')+text_type.count('围绕')+text_type.count('伟大')+text_type.count('位于')+text_type.count('污染')+text_type.count('无比')+text_type.count('无法')+text_type.count('无穷')+text_type.count('无限')+text_type.count('武装')+text_type.count('吸取')+text_type.count('袭击')+text_type.count('喜爱')+text_type.count('显示')+text_type.count('限制')+text_type.count('陷入')+text_type.count('相互')+text_type.count('详细')+text_type.count('响应')+text_type.count('享受')+text_type.count('象征')+text_type.count('消除')+text_type.count('消耗')+text_type.count('小心')+text_type.count('写作')+text_type.count('辛勤')+text_type.count('修改')+text_type.count('修正')+text_type.count('修筑')+text_type.count('选择')+text_type.count('严格')+text_type.count('严禁')+text_type.count('严厉')+text_type.count('严密')+text_type.count('严肃')+text_type.count('研制')+text_type.count('延长')+text_type.count('掩盖')+text_type.count('养成')+text_type.count('一经')+text_type.count('依法')+text_type.count('依旧')+text_type.count('依然')+text_type.count('抑制')+text_type.count('应用')+text_type.count('永远')+text_type.count('踊跃')+text_type.count('游览')+text_type.count('予以')+text_type.count('遇到')+text_type.count('预防')+text_type.count('预习')+text_type.count('阅读')+text_type.count('运用')+text_type.count('再三')+text_type.count('遭到')+text_type.count('遭受')+text_type.count('遭遇')+text_type.count('增加')+text_type.count('增进')+text_type.count('增强')+text_type.count('占领')+text_type.count('占有')+text_type.count('战胜')+text_type.count('掌握')+text_type.count('照例')+text_type.count('镇压')+text_type.count('征服')+text_type.count('征求')+text_type.count('争夺')+text_type.count('争论')+text_type.count('整顿')+text_type.count('证明')+text_type.count('直到')+text_type.count('执行')+text_type.count('制定')+text_type.count('制订')+text_type.count('制造')+text_type.count('治疗')+text_type.count('中断')+text_type.count('重大')+text_type.count('专心')+text_type.count('转入')+text_type.count('转移')+text_type.count('装备')+text_type.count('装饰')+text_type.count('追求')+text_type.count('自学')+text_type.count('综合')+text_type.count('总结')+text_type.count('阻止')+text_type.count('钻研')+text_type.count('遵守')+text_type.count('左右')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.42\n",
      "41.04\n",
      "51.15\n",
      "53.86\n",
      "51.73\n",
      "46.62\n",
      "42.14\n",
      "36.11\n",
      "40.64\n",
      "36.28\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (disyllabic(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.08"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disyllabic(reportage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 48 verb reduplication\n",
    "#想想、看看、听听、走走、说说、玩玩、吃吃、喝喝\n",
    "def verb_dp(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('想想')+text_type.count('看看')+text_type.count('听听')\\\n",
    "    +text_type.count('走走')+text_type.count('说说')+text_type.count('吃吃')+text_type.count('喝喝')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.19\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.16\n",
      "0.15\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (verb_dp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.03\n",
      "0.0\n",
      "0.02\n",
      "0.01\n",
      "0.09\n",
      "0.07\n",
      "0.0\n",
      "0.02\n",
      "0.2\n",
      "0.36\n",
      "0.54\n",
      "0.27\n",
      "0.18\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (verb_dp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 50 particles \n",
    "def particle(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('呃')+text_type.count('吗')+text_type.count('呀')\\\n",
    "    +text_type.count('啊')+text_type.count('啊啊')+text_type.count('呢')+text_type.count('嘛')\\\n",
    "    +text_type.count('吧')+text_type.count('啦')+text_type.count('了')+text_type.count('喽')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.8\n",
      "29.64\n",
      "30.5\n",
      "21.37\n",
      "26.39\n",
      "49.59\n",
      "40.99\n",
      "36.55\n",
      "41.76\n",
      "41.72\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (particle(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.23\n",
      "8.34\n",
      "11.53\n",
      "12.41\n",
      "3.15\n",
      "18.57\n",
      "16.2\n",
      "1.81\n",
      "5.98\n",
      "22.36\n",
      "25.3\n",
      "21.11\n",
      "21.87\n",
      "28.11\n",
      "36.13\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (particle(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 42 classical syntax - words \n",
    "def classical(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('备受')+text_type.count('言必称')+text_type.count('并存')+text_type.count('不得而')+text_type.count('抑且')+text_type.count('不特')+text_type.count('不外乎')+text_type.count('且')+text_type.count('不外乎')+text_type.count('不相')+text_type.count('中不乏')+text_type.count('不啻')+text_type.count('称之为')+text_type.count('称之')+text_type.count('充其量')+text_type.count('出于')+text_type.count('处于')+text_type.count('不次于')+text_type.count('从属于')+text_type.count('从中')+text_type.count('得自于')+text_type.count('得力于')+text_type.count('予以')+text_type.count('给予')+text_type.count('加以')+text_type.count('深具')+text_type.count('之能事')+text_type.count('发轫于')+text_type.count('凡此')+text_type.count('大抵')+text_type.count('凡')+text_type.count('所能及')+text_type.count('所可比')+text_type.count('非但')+text_type.count('庶可')+text_type.count('之故')+text_type.count('工于')+text_type.count('苟')+text_type.count('顾')+text_type.count('广为')+text_type.count('果')+text_type.count('核以')+text_type.count('何其')+text_type.count('或可')+text_type.count('跻身')+text_type.count('跻于')+text_type.count('不日即')+text_type.count('藉')+text_type.count('之大成')+text_type.count('再加')+text_type.count('略加')+text_type.count('详加')+text_type.count('以俱来')+text_type.count('见胜')+text_type.count('见长')+text_type.count('兼')+text_type.count('渐次')+text_type.count('化')+text_type.count('混同于')+text_type.count('归之于')+text_type.count('推广到')+text_type.count('名之为')+text_type.count('引为')+text_type.count('矣')+text_type.count('较')+text_type.count('借以')+text_type.count('尽其')+text_type.count('略陈己见')+text_type.count('而言')+text_type.count('而论')+text_type.count('决定于')+text_type.count('之先河')+text_type.count('苦不能')+text_type.count('莫不是')+text_type.count('乃')+text_type.count('泥于')+text_type.count('偏于')+text_type.count('颇有')+text_type.count('岂不')+text_type.count('岂可')+text_type.count('乎')+text_type.count('哉')+text_type.count('起源于')+text_type.count('何况')+text_type.count('切于')+text_type.count('取信于')+text_type.count('如')+text_type.count('则')+text_type.count('若')+text_type.count('岂')+text_type.count('舍')+text_type.count('甚于')+text_type.count('时年')+text_type.count('时值')+text_type.count('使之')+text_type.count('有别于')+text_type.count('倍加')+text_type.count('所在')+text_type.count('示人以')+text_type.count('随致')+text_type.count('之所以')+text_type.count('所以然')+text_type.count('所verb者')+text_type.count('无所')+text_type.count('有所')+text_type.count('皆指')+text_type.count('所引致')+text_type.count('罕为')+text_type.count('鲜为')+text_type.count('多为')+text_type.count('唯')+text_type.count('尚未')+text_type.count('无一不')+text_type.count('无不能')+text_type.count('无从')+text_type.count('可见')+text_type.count('毋宁')+text_type.count('无宁')+text_type.count('务')+text_type.count('系于')+text_type.count('仅限于')+text_type.count('方能')+text_type.count('需')+text_type.count('须')+text_type.count('许之为')+text_type.count('一改')+text_type.count('一变')+text_type.count('与否')+text_type.count('业已')+text_type.count('不以为然')+text_type.count('为能')+text_type.count('为多')+text_type.count('为最')+text_type.count('以期')+text_type.count('不宜')+text_type.count('宜于')+text_type.count('异于')+text_type.count('益见')+text_type.count('抑或')+text_type.count('故')+text_type.count('之便')+text_type.count('应推')+text_type.count('着手')+text_type.count('着眼')+text_type.count('可证')+text_type.count('可知')+text_type.count('可见')+text_type.count('而成')+text_type.count('有不')+text_type.count('有所')+text_type.count('有待于')+text_type.count('有赖于')+text_type.count('有助于')+text_type.count('有进于')+text_type.count('之分')+text_type.count('之别')+text_type.count('多有')+text_type.count('囿于')+text_type.count('与之')+text_type.count('同/共')+text_type.count('同为')+text_type.count('欲')+text_type.count('必')+text_type.count('喻之')+text_type.count('曰')+text_type.count('之际')+text_type.count('已然')+text_type.count('在于')+text_type.count('则')+text_type.count('者')+text_type.count('即是')+text_type.count('皆是')+text_type.count('云者')+text_type.count('者有之')+text_type.count('首属')+text_type.count('首推')+text_type.count('莫过于')+text_type.count('之')+text_type.count('之于')+text_type.count('置身于')+text_type.count('转而')+text_type.count('自')+text_type.count('自况')+text_type.count('自命')+text_type.count('自诩')+text_type.count('自认')+text_type.count('自居')+text_type.count('自许')+text_type.count('以降')+text_type.count('足以')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.17\n",
      "4.37\n",
      "3.86\n",
      "2.95\n",
      "2.49\n",
      "4.3\n",
      "4.41\n",
      "4.26\n",
      "2.11\n",
      "2.78\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (classical(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.83"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(reportage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.58"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(editorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.89"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.88"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(religion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.74"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.98"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.62"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(biography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.17"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(official)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.54"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(academic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.29"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(general_fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.61"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(mystery_fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.97"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(sci_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.43"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(adventure_fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.39"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(romantic_fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.03"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical(humor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 59 dialect\n",
    "def dialect(text_type):\n",
    "    def raw(text_type): \n",
    "        return text_type.count('偶')+text_type.count('欢喜')+text_type.count('晓得')\\\n",
    "    +text_type.count('啥子')+text_type.count('埋汰')+text_type.count('扑街')\n",
    "    def normalized(text_type): \n",
    "        return raw(text_type) / len(text_type)\n",
    "    return round(normalized (text_type) * 1000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.39\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for text in OC_type: \n",
    "    print (dialect(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.33\n",
      "0.0\n",
      "0.07\n",
      "0.09\n",
      "0.0\n",
      "0.02\n",
      "0.1\n",
      "0.03\n",
      "0.0\n",
      "0.03\n",
      "0.1\n",
      "0.14\n"
     ]
    }
   ],
   "source": [
    "for text in text_type:\n",
    "    print (dialect(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
